{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeNkOj1hFk2yPt503AnWGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrankGangWang/AppliedML_Python_Coursera/blob/master/Exeter_Test_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction methods:\n",
        "1. spatial autocorrelation of alist of lags per sample;\n",
        "2. histogram per sample;\n",
        "\n",
        "There are 3 general approaches to encoding sequence data:\n",
        "\n",
        "Ordinal encoding DNA Sequence\n",
        "\n",
        "One-hot encoding DNA Sequence\n",
        "\n",
        "DNA sequence as a “language”, known as k-mer counting\n",
        "\n",
        "\n",
        "Ref:\n",
        "https://www.theaidream.com/post/demystify-dna-sequencing-with-machine-learning-and-python\n"
      ],
      "metadata": {
        "id": "zivjTsUMPB8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ordinal encoding DNA sequence data: 'NATGC'=[0.0, .25,.5, .75, 1.0]\n",
        "import numpy as np\n",
        "import re\n",
        "def string_to_array(seq_string):\n",
        "   seq_string = seq_string.lower()\n",
        "   seq_string = re.sub('[^acgt]', 'n', seq_string)\n",
        "   seq_string = np.array(list(seq_string))\n",
        "   return seq_string\n",
        "# create a label encoder with 'acgtn' alphabet\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))\n",
        "def ordinal_encoder(my_array):\n",
        "   integer_encoded = label_encoder.transform(my_array)\n",
        "   float_encoded = integer_encoded.astype(float)\n",
        "   float_encoded[float_encoded == 0] = 0.25 # A\n",
        "   float_encoded[float_encoded == 1] = 0.50 # C\n",
        "   float_encoded[float_encoded == 2] = 0.75 # G\n",
        "   float_encoded[float_encoded == 3] = 1.00 # T\n",
        "   float_encoded[float_encoded == 4] = 0.00 # anything else, lets say n\n",
        "   return float_encoded\n"
      ],
      "metadata": {
        "id": "W-NHq-OCW6dz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s try out a simple short sequence:\n",
        "seq_test = 'TTCAGCCAGTG'\n",
        "ordinal_encoder(string_to_array(seq_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVwFfnGoXIHg",
        "outputId": "213665f1-3c74-4f65-ca5b-403e423d558e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.  , 1.  , 0.5 , 0.25, 0.75, 0.5 , 0.5 , 0.25, 0.75, 1.  , 0.75])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding DNA Sequence\n",
        "\n",
        "Another approach is to use one-hot encoding to represent the DNA sequence. This is widely used in deep learning methods and lends itself well to algorithms like convolutional neural networks. In this example, “ATGC” would become [0,0,0,1], [0,0,1,0], [0,1,0,0], [1,0,0,0]. And these one-hot encoded vectors can either be concatenated or turned into 2-dimensional arrays.\n"
      ],
      "metadata": {
        "id": "1K3DHprVX3i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def one_hot_encoder(seq_string):\n",
        "   int_encoded = label_encoder.transform(seq_string)\n",
        "   onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
        "   int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
        "   onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n",
        "   onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
        "   return onehot_encoded\n",
        "\n",
        "#So let’s try it out with a simple short sequence:\n",
        "seq_test = 'GAATTCTCGAA'\n",
        "one_hot_encoder(string_to_array(seq_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMcist9GXILG",
        "outputId": "4dfa0b5f-3662-4cdd-9c79-0ce0c3738288"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNA sequence as a “language”, known as k-mer counting\n",
        "\n",
        "A hurdle that still remains is that none of these above methods results in vectors of uniform length, and that is a necessity for feeding data to a classification or regression algorithm. So with the above methods, you have to resort to things like truncating sequences or padding with “n” or “0” to get vectors of uniform length.\n",
        "\n",
        "\n",
        "DNA and protein sequences can be seen as the language of life. The language encodes instructions as well as functions for the molecules that are found in all life forms. The sequence language resemblance continues with the genome as the book, subsequences (genes and gene families) are sentences and chapters, k-mers and peptides are words, and nucleotide bases and amino acids are the alphabets. Since the relationship seems so likely, it stands to reason that natural language processing(NLP) should also implement the natural language of DNA and protein sequences.\n",
        "\n",
        "\n",
        "The method we use here is manageable and easy. We first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if we use “words” of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
        "\n",
        "\n",
        "In genomics, we refer to these types of manipulations as “k-mer counting”, or counting the occurrences of each possible k-mer sequence and Python natural language processing tools make it super easy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WjUipZxoYWGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Kmers_funct(seq, size):\n",
        "   return [ seq[x:x+size].lower() for x in range(len(seq) - size + 1) ]\n",
        "\n",
        "#So let’s try it out with a simple sequence:\n",
        "\n",
        "\n",
        "mySeq = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
        "Kmers_funct(mySeq, size=7)\n",
        "#GTGCCCAGGTTCAGTGAGTGACACAGGCAG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHGg5SGXICL",
        "outputId": "8d939f1d-8b92-4c7f-80c2-2bd83251c178"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gtgccca',\n",
              " 'tgcccag',\n",
              " 'gcccagg',\n",
              " 'cccaggt',\n",
              " 'ccaggtt',\n",
              " 'caggttc',\n",
              " 'aggttca',\n",
              " 'ggttcag',\n",
              " 'gttcagt',\n",
              " 'ttcagtg',\n",
              " 'tcagtga',\n",
              " 'cagtgag',\n",
              " 'agtgagt',\n",
              " 'gtgagtg',\n",
              " 'tgagtga',\n",
              " 'gagtgac',\n",
              " 'agtgaca',\n",
              " 'gtgacac',\n",
              " 'tgacaca',\n",
              " 'gacacag',\n",
              " 'acacagg',\n",
              " 'cacaggc',\n",
              " 'acaggca',\n",
              " 'caggcag']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It returns a list of k-mer “words.” You can then join the “words” into a “sentence”, then apply your favorite natural language processing methods to the “sentences” as you normally would.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rEkn6wdHY6gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = Kmers_funct(mySeq, size=6)\n",
        "joined_sentence = ' '.join(words)\n",
        "joined_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6EGOA-pnXH9x",
        "outputId": "eb31bd7f-dc31-4e9e-cfe0-2b660dc3766f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tune both the word length and the amount of overlap. This allows you to determine how the DNA sequence information and vocabulary size will be important in your application. For example, if you use words of length 6, and there are 4 letters, you have a vocabulary of size 4096 possible words. You can then go on and create a bag-of-words model like you would in NLP.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "95ly3k6qZMB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s make a couple more “sentences” to make it more interesting.\n",
        "mySeq1 = 'TCTCACACATGTGCCAATCACTGTCACCC'\n",
        "mySeq2 = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
        "sentence1 = ' '.join(Kmers_funct(mySeq1, size=6))\n",
        "sentence2 = ' '.join(Kmers_funct(mySeq2, size=6))\n",
        "\n",
        "#Creating the Bag of Words model:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()"
      ],
      "metadata": {
        "id": "U5HOeUmnY6A2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(len(sentence1), len(mySeq1), len(sentence1.split()))\n",
        "print(len(sentence2), len(mySeq2), len(sentence2.split()) )\n",
        "print(len(joined_sentence), len(mySeq), len(joined_sentence.split()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i865zuziGUi",
        "outputId": "39d09bf4-9723-4a46-c1c5-9af10f8f4c0a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 49)\n",
            "167 29 24\n",
            "174 30 25\n",
            "174 30 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(np.unique([joined_sentence, sentence1, sentence2]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exPzj8tUimHU",
        "outputId": "1de296c0-85d8-46db-d1cc-ba793fc7c5c6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag',\n",
              "       'tctcac ctcaca tcacac cacaca acacat cacatg acatgt catgtg atgtgc tgtgcc gtgcca tgccaa gccaat ccaatc caatca aatcac atcact tcactg cactgt actgtc ctgtca tgtcac gtcacc tcaccc'],\n",
              "      dtype='<U174')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(np.unique(joined_sentence.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence1.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence2.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence1.split()+ sentence2.split())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZduAm2u4ld6J",
        "outputId": "d10fc6cf-147e-4b73-eddb-2f397f78a58b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 49 25 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdefe5Hch8sa",
        "outputId": "1cc491bb-6bd3-41f2-8b7c-f4fac7f4119b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "        0, 1, 0, 0, 1],\n",
              "       [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "        0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('joined_sentence=',joined_sentence, '\\n', 'sentence1=\\t', sentence1, '\\n','sentence2=\\t',sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7C3EpemY57n",
        "outputId": "226462ac-4648-443a-f1b3-576e643674e8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joined_sentence= gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag \n",
            " sentence1=\t tctcac ctcaca tcacac cacaca acacat cacatg acatgt catgtg atgtgc tgtgcc gtgcca tgccaa gccaat ccaatc caatca aatcac atcact tcactg cactgt actgtc ctgtca tgtcac gtcacc tcaccc \n",
            " sentence2=\t gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Bag of Words model:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()\n"
      ],
      "metadata": {
        "id": "b1iyuyK0g8oe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "r50Orqv3Y53P",
        "outputId": "b8455418-6d1b-4d19-8729-ce2a2e657ee3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtH-zCbUhtuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gy9hoKSOhtot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opKm_-HLhtiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_count_chars(line, counter):\n",
        "  \"\"\"func to get unique chars in 'line' based on current 'counter'.\n",
        "  Note: set counter = set() for the first line;\n",
        "  \"\"\"\n",
        "  for c in line:\n",
        "    counter.add(c)\n",
        "  return (counter)\n",
        "  #sorted(set) returns a list"
      ],
      "metadata": {
        "id": "iBtNTKRvQ30s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "pBhzIuZkm4Zp",
        "outputId": "1076877e-99b8-4e11-d257-37dc64fb9fb1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a348699978ee>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchars_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unique set of chars in all samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcount_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
          ]
        }
      ],
      "source": [
        "chars_list = set() # unique set of chars in all samples\n",
        "\n",
        "f = open(\"test.txt\", \"r\")\n",
        "\n",
        "count_chars = 0\n",
        "for number_of_lines, line in enumerate(f):\n",
        "  line = line.rstrip('\\n')\n",
        "  count_chars += len(line)\n",
        "  chars_list = func_count_chars(line, chars_list)\n",
        "\n",
        "  if number_of_lines<5:\n",
        "    print(f'Line {number_of_lines}: \\t {len(line)} chars, last 5 ={line[-5:]},\\\n",
        "    count={len(line)},\\t total ={count_chars},\\t uniques={sorted(chars_list)}')\n",
        "\n",
        "f.close()\n",
        "number_of_lines = number_of_lines + 1\n",
        "chars_list = sorted(chars_list) # not chars_list is a list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ocDtKV2CFojw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of lines=', number_of_lines)\n",
        "print('number of chars \\t=', count_chars)\n",
        "#print('sum counts per char\\t=', func_sum_counts(chars_list))\n",
        "print('counts per char=', chars_list)"
      ],
      "metadata": {
        "id": "zRDgBBtanWfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdGXld5GQKDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def func_count_chars_ordered(line, chars):\n",
        "  \"\"\"func to count number of strings in string 'line' based on current 'counter'.\n",
        "  Note: set counter = {} for the first line;\n",
        "  \"\"\"\n",
        "  counter = np.zeros((len(chars, )))\n",
        "  #print(counter, line, chars)\n",
        "  for id, c in enumerate(chars):\n",
        "    #print(f'id={id}, ch={chars[id]}')\n",
        "    counter[id] = line.count(chars[id])\n",
        "  return counter\n"
      ],
      "metadata": {
        "id": "AMcQdvOQsDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = func_count_chars_ordered('ABC DEFGDEFG DDD', chars_list)\n",
        "tmp = [{chars_list[id]:tmp[id]} for id in range(len(chars_list))]\n",
        "print(tmp)"
      ],
      "metadata": {
        "id": "R20I5z32stRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = np.zeros((number_of_lines, len(chars_list)))\n",
        "print(chars_list, df.shape)\n",
        "\n",
        "f = open(\"test.txt\", \"r\")\n",
        "for c, line in enumerate(f):\n",
        "  if c<5:\n",
        "    print(f'***num of chars in line {c} is {len(line), {line[-5:]}}')\n",
        "  line = line.rstrip('\\n')\n",
        "  df[c] = func_count_chars_ordered(line, chars_list)\n",
        "f.close()\n",
        "\n",
        "df = pd.DataFrame(df, columns=chars_list)\n"
      ],
      "metadata": {
        "id": "tQXxDN2EnWbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "oj6jEjZMnWYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Qh-zGwzFWDJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]"
      ],
      "metadata": {
        "id": "knHKSzJJXOc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.lag_plot(line, lag=1)\n"
      ],
      "metadata": {
        "id": "SoVGprmBXEJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.lag_plot(df, lag=1)\n"
      ],
      "metadata": {
        "id": "9MKasRZ2nWVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.lag_plot(df, lag=2)\n"
      ],
      "metadata": {
        "id": "s1DlAuACWnaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NByjlhCKWxh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n--y2rpSWxeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cGrehw3Wxa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YFEYJnoWxXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "# calculate summary statistics\n",
        "data_mean, data_std = mean(df), std(df)\n",
        "# identify outliers\n",
        "cut_off = data_std * 2\n",
        "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
        "# identify outliers\n",
        "for ch in chars:\n",
        "  outliers = [x for x in df[ch] if x < lower[ch] or x > upper[ch]]\n",
        "  outliers_idx = df.index[df[ch]==outliers[0]].tolist()\n",
        "\n",
        "  print(ch, outliers, '\\n', outliers_idx)"
      ],
      "metadata": {
        "id": "DhY1tZUgnWSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['C']==14.0\n",
        "df.index[df['C']==14.0].tolist()\n"
      ],
      "metadata": {
        "id": "7NSfAJmCxymr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YbCFUfaxych"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean, data_std"
      ],
      "metadata": {
        "id": "ZghcdQnMwwgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower, upper"
      ],
      "metadata": {
        "id": "O8MVt1yxwwYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['C']"
      ],
      "metadata": {
        "id": "qJIBM2j4xNd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "U4XHHcd4wwVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9tg4HDpzoUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "#create a histogram\n",
        "\n",
        "fig = px.histogram(df, x='C')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SE3TQux2zoRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a box plot\n",
        "\n",
        "fig = px.box(df, y='C')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "T8lWk-h4zoOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "id": "P5w5Un_30PUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(x=df['C'], y=df['D'])\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7AIMvs0dzoLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "X = [[-1.1], [0.2], [101.1], [0.3]]\n",
        "clf = LocalOutlierFactor(n_neighbors=2)\n",
        "print(clf.fit_predict(X))\n",
        "\n",
        "print(clf.negative_outlier_factor_)\n"
      ],
      "metadata": {
        "id": "8TZtoIWx2NVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = 50\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df)\n",
        "print(np.where(results==-1))"
      ],
      "metadata": {
        "id": "O-zaILWG2NRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = 100\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df)\n",
        "print(np.where(results==-1))"
      ],
      "metadata": {
        "id": "TBdEeaXlArau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "#Note that neighbors.LocalOutlierFactor does not support predict, decision_function\n",
        "#and score_samples methods by default but only a fit_predict method, as this estimator\n",
        "#was originally meant to be applied for outlier detection. The scores of abnormality\n",
        "#of the training samples are accessible through the negative_outlier_factor_ attribute.\n",
        "\n",
        "n_neighbors = 150\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df) #\n",
        "print(np.where(results==-1))\n",
        "#estimator.predict(X_test): Inliers are labeled 1, while outliers are labeled -1.\n",
        "#clf.negative_outlier_factor_\n",
        "#The decision_function method is also defined from the scoring function, in such\n",
        "#a way that negative values are outliers and non-negative ones are inliers:\n",
        "#estimator.decision_function(X_test)\n",
        "\n",
        "#negative_outlier_factor_: The opposite LOF of the training samples. The higher, the more normal.\n",
        "#Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1), while outliers tend to have a larger LOF score.\n"
      ],
      "metadata": {
        "id": "WX94zj-XAmeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[np.where(results==-1)].T"
      ],
      "metadata": {
        "id": "E-DcAW5z2yZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = 50\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df)\n",
        "print(np.where(results==-1))\n",
        "print(df.iloc[np.where(results==-1)].T)\n"
      ],
      "metadata": {
        "id": "bSQAAVIEBIhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[np.where(results==-1)]"
      ],
      "metadata": {
        "id": "vt8YZz_3AwGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[[1,2]]"
      ],
      "metadata": {
        "id": "-4zbZpkKKVfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column=['C', 'D', 'F'])\n"
      ],
      "metadata": {
        "id": "VVu2UsN9JbmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot()\n"
      ],
      "metadata": {
        "id": "mI31HeP34CIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column=['E', 'G'])\n"
      ],
      "metadata": {
        "id": "6NU3FYBmKNyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "8LAfiqHw4CNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.negative_outlier_factor_)"
      ],
      "metadata": {
        "id": "lfaqvgsv2NNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7dE4QH8A2NKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py\n",
        "\n",
        "Outlier detection with Local Outlier Factor (LOF)\n"
      ],
      "metadata": {
        "id": "DVmYbnlqPDS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X_inliers = 0.3 * np.random.randn(100, 2)\n",
        "X_inliers = np.r_[X_inliers + 2, X_inliers - 2]\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "X = np.r_[X_inliers, X_outliers]\n",
        "\n",
        "n_outliers = len(X_outliers)\n",
        "ground_truth = np.ones(len(X), dtype=int)\n",
        "ground_truth[-n_outliers:] = -1"
      ],
      "metadata": {
        "id": "EqeZWZAWPETq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_inliers.shape, np.random.randn(100, 2).shape, X_outliers.shape, n_outliers, X.shape"
      ],
      "metadata": {
        "id": "u-OwZoqePaj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbYzTOmxPaUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "y_pred = clf.fit_predict(X)\n",
        "n_errors = (y_pred != ground_truth).sum()\n",
        "X_scores = clf.negative_outlier_factor_"
      ],
      "metadata": {
        "id": "tlygJ2moPN77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.legend_handler import HandlerPathCollection\n",
        "\n",
        "\n",
        "def update_legend_marker_size(handle, orig):\n",
        "    \"Customize size of the legend marker\"\n",
        "    handle.update_from(orig)\n",
        "    handle.set_sizes([20])\n",
        "\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], color=\"k\", s=3.0, label=\"Data points\")\n",
        "# plot circles with radius proportional to the outlier scores\n",
        "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
        "scatter = plt.scatter(\n",
        "    X[:, 0],\n",
        "    X[:, 1],\n",
        "    s=1000 * radius,\n",
        "    edgecolors=\"r\",\n",
        "    facecolors=\"none\",\n",
        "    label=\"Outlier scores\",\n",
        ")\n",
        "plt.axis(\"tight\")\n",
        "plt.xlim((-5, 5))\n",
        "plt.ylim((-5, 5))\n",
        "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
        "plt.legend(\n",
        "    handler_map={scatter: HandlerPathCollection(update_func=update_legend_marker_size)}\n",
        ")\n",
        "plt.title(\"Local Outlier Factor (LOF)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jgldZkclPQUS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}