{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final Interview for DataScience - 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrankGangWang/AppliedML_Python_Coursera/blob/master/Copy_of_Final_Interview_for_DataScience_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqlyZk0Z-kf0"
      },
      "source": [
        "**Interview questions to test data science skills**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aR3yaVg-6FC"
      },
      "source": [
        "# Let's load the data from public GitHub account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMU3MFw0-ZRS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load data and check condation of NA\n",
        "df = pd.read_pickle(\"https://github.com/manjiler/interview_for_datascience/raw/master/interview_storage.pkl\")\n",
        "df['timestamp_seconds'] = df.pop('timestamp')/1.0e3\n",
        "\n",
        "# add sorted datetime index\n",
        "df.set_index(pd.to_datetime(df['timestamp_seconds'], unit='s', origin='unix'), inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Constants\n",
        "SYSTEM_ID_SELECTED = ['sys1'] #['All']\n",
        "TEST_SIZE = 0.2 # Not yet used\n",
        "# NOTE: As PowerTransform only accept positive inputs thus separately process transformed times\n",
        "USE_TIME_TRANSFORMED = True \n",
        "USE_TIME_STAMP = True\n",
        "\n",
        "# We separately process sub-sets of columns and concatenate them in a numpy array called data \n",
        "target_col = ['cpu_utilization']\n",
        "numerical_transform_cols = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "                            'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz']\n",
        "time_col = ['timestamp_seconds']\n",
        "time_transformed_cols = ['Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos']\n",
        "cols_to_encode = ['systemId', 'model_type']\n",
        "\n",
        "#AS timestamp_seconds is appended after numerical_transform_cols are added to data\n",
        "# As feature selection can be RFE thus standarize/normalize data first;\n",
        "# Feature selection also cause time poition dymanic thus need be decided after all feature selection\n",
        "TIMESTAMP_INDEX_BEFORE_FS = len(target_col) + len(time_col) + len(numerical_transform_cols) - 1 \n",
        "\n",
        "Y_INDEX_DATA = 0 # index of target in data\n",
        "X_FIRST_INDEX_DATA = 1 # first index in data for X\n",
        "\n",
        "hour = 60*60\n",
        "day = 24*hour\n",
        "week = 7*day\n",
        "\n",
        "data_cols = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbq-3PQo0XLj",
        "outputId": "d1add901-8244-499c-ba4d-ab929c9b74f4"
      },
      "source": [
        "print(df[df['systemId']==SYSTEM_ID_SELECTED[0]].loc[:, ['systemId', 'model_type', 'cpu_utilization']] .head(5))\n",
        "print(df[df['systemId']==SYSTEM_ID_SELECTED[0]].loc[:, ['systemId', 'model_type', 'cpu_utilization']] .tail(5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    systemId model_type  cpu_utilization\n",
            "timestamp_seconds                                       \n",
            "2019-11-01 04:25:00     sys1          A        23.083557\n",
            "2019-11-01 04:30:00     sys1          A        18.258795\n",
            "2019-11-01 04:35:00     sys1          A        17.899469\n",
            "2019-11-01 04:40:00     sys1          A        20.296371\n",
            "2019-11-01 04:45:00     sys1          A        18.300312\n",
            "                    systemId model_type  cpu_utilization\n",
            "timestamp_seconds                                       \n",
            "2019-11-30 23:35:00     sys1          A        24.737446\n",
            "2019-11-30 23:40:00     sys1          A        19.898367\n",
            "2019-11-30 23:45:00     sys1          A        22.392872\n",
            "2019-11-30 23:50:00     sys1          A        24.213583\n",
            "2019-11-30 23:55:00     sys1          A        18.350607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5JuXIE74pFy"
      },
      "source": [
        "# check missing data; result: no missing data\n",
        "print(f'*** There are {df.isna().sum().sum()} NA data')\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANYv7bdPEdpX"
      },
      "source": [
        "## Now that the data is loaded. let's begin!!!\n",
        "\n",
        "# **About the data**\n",
        "\n",
        "---\n",
        "This is time series data for one month collected for N number of devices\n",
        "\n",
        "Columns\n",
        "\n",
        "systemId - Device name\n",
        "\n",
        "timestamp_seconds - epoch time when the sensor data was collected\n",
        "\n",
        "model_type - Different versions/release/model of the device (similar to mobile models)\n",
        "\n",
        "cpu_utilization - this percentage of how much the CPU is used on the device.\n",
        "\n",
        "read_cache_miss - Percentage of read that were not present in the Cache\n",
        "\n",
        "write_cache_miss - Percentage of write that were not present in the Cache\n",
        "\n",
        "read_iops -  Number of read IOs per second (Input/Output)\n",
        "\n",
        "write_iops -  Nummber of write IOs per second (Input/Output)\n",
        "\n",
        "read_throughput - the read bandwidth per second (Units kbps)\n",
        "\n",
        "write_throughput - the write bandwidth per second (Units kbps)\n",
        "\n",
        "read_iosz - the block size for read Input/Output operations\n",
        "\n",
        "write_iosz - the block size for write Input/Output operations\n",
        "\n",
        "\n",
        "y -> cpu_utilization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw8r7vKGEklC"
      },
      "source": [
        "## Q1. Do an EDA on the data, correlation plots, features that might be important for the modeling. Share your observations. Comment on how the data looks from modeling perspective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhvgbIJNOakr"
      },
      "source": [
        "# plot utilities\n",
        "# plot histogram of systemId_selected\n",
        "def plot_df_hist(df_tmp, systemId_selected, title_str, cols, bins):\n",
        "  if systemId_selected[0] != 'All':\n",
        "    df_tmp = df_tmp[df_tmp['systemId']==systemId_selected[0]]\n",
        "  df_tmp = df_tmp[cols]\n",
        "  df_tmp.hist(bins=bins)\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 8)\n",
        "  fig.suptitle(f'{title_str}, systemId {systemId_selected[0]}')\n",
        "  plt.tight_layout()\n",
        "  fig.subplots_adjust(top=0.9)\n",
        "\n",
        "# utility hist2d plot xcols against target ycol\n",
        "def hist2d_plot(df_temp, systemId, xcols, ycol, xbins, ybins, vmax):\n",
        "  print(f\"hist2d_plot 1 Initial address of df_temp: {id(df_temp)}, shape={df_temp.shape}\")\n",
        "  if systemId != 'All': \n",
        "    df_temp = df[df['systemId']==systemId[0]]\n",
        "  print(f\"hist2d_plot 2 Initial address of df_temp: {id(df_temp)}, shape={df_temp.shape}\")\n",
        "  print(df_temp.shape)\n",
        "  len_x = len(xcols)\n",
        "  num_rows = math.ceil(math.sqrt(len_x))\n",
        "  num_cols = math.ceil(len_x/num_rows)\n",
        "  x_index = 0\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      if x_index == len_x:\n",
        "        break\n",
        "      plt.subplot(num_rows, num_cols, x_index+1)\n",
        "      plt.hist2d(df_temp[xcols[x_index]], df_temp[ycol], bins=[xbins, ybins], vmax=vmax) #\n",
        "      plt.colorbar()\n",
        "      plt.xlabel(xcols[x_index])\n",
        "      plt.ylabel(ycol)\n",
        "      x_index = x_index + 1\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18.5, 3*num_rows)\n",
        "  fig.suptitle(f'systemId={systemId}')\n",
        "  plt.tight_layout() # 2nd last step in fig setting\n",
        "  fig.subplots_adjust(top=0.88) # last in fig setting\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y479tMw7kg3v"
      },
      "source": [
        "# add some artificial features maybe useful for classification\n",
        "# add sin/cos for day/hour\n",
        "# To help finding time periodicity (hourly/daily/weekly/monthly/yearly), \n",
        "#    add additional features like \"time of day/week\" by appling cos and sin to timestamp_seconds \n",
        "df['Hour_Sin'] = np.sin(df['timestamp_seconds'] * (2 * np.pi / hour))\n",
        "df['Hour_Cos'] = np.cos(df['timestamp_seconds'] * (2 * np.pi / hour))\n",
        "df['Day_Sin'] = np.sin(df['timestamp_seconds'] * (2 * np.pi / day))\n",
        "df['Day_Cos'] = np.cos(df['timestamp_seconds'] * (2 * np.pi / day))\n",
        "week_offset = 3*day # as epoch 0 is Thursday 1970-01-01, and leap seconds 23:59:60\n",
        "df['Week_Sin'] = np.sin((df['timestamp_seconds']+week_offset) * (2 * np.pi / week))\n",
        "df['Week_Cos'] = np.cos((df['timestamp_seconds']+week_offset) * (2 * np.pi / week))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edyDh42I8B-T"
      },
      "source": [
        "# RUN: plot hist\n",
        "# Conclusion: a few columns are far from Gaussian distribution\n",
        "title_str = 'Before transformation!'\n",
        "plot_df_hist(df, SYSTEM_ID_SELECTED, title_str, df.columns, 30)\n",
        "#NOTE: Hour_Sin AND Hour_Cos have only 7 distinct bins at [0, 30, 60, 90, -30, -60, -90] degress as \n",
        "# as sampling perid=5 minutes, thus 2pi*5min/60min=pi/6=30degree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOwZ76uV-RDA"
      },
      "source": [
        "The histograms show that we need apply normalization and power transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtyLQmcWebEX"
      },
      "source": [
        "#Plot hist2d: xcols against target ycol\n",
        "vmax = 100; xbins = 50; ybins = 50\n",
        "ycol = 'cpu_utilization'\n",
        "xcols_group = [\n",
        "  ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops'],\n",
        "  ['read_throughput', 'write_throughput', 'read_iosz', 'write_iosz'],\n",
        "  ['Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos']]\n",
        "for xcols in xcols_group:\n",
        "  hist2d_plot(df, SYSTEM_ID_SELECTED, xcols, ycol, xbins, ybins, vmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyZK_I3QuroN"
      },
      "source": [
        "df.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vMT39fHGAh9"
      },
      "source": [
        "# All pre-processing functions\n",
        "# Transform to make data more Gaussian-like \n",
        "# Standarize to make close Norml(0, 1)\n",
        "# Only to numerical_transform_cols, not for timestamp, categoricals\n",
        "def get_target_for_transform(df, systemId_selected, numerical_transform_cols, print_flag=False):\n",
        "  from sklearn.preprocessing import PowerTransformer\n",
        "  #from sklearn.preprocessing import QuantileTransformer\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df[numerical_transform_cols]\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]][numerical_transform_cols]\n",
        "  if print_flag:\n",
        "    print(f'*** Inside get_target_for_transform(): df_tmp.shape={df_tmp.shape}')\n",
        "  # Start Transformation\n",
        "  data = df_tmp.values\n",
        "  return data\n",
        "\n",
        "# Transform to make data more Gaussian-like \n",
        "# Standarize to make close Norml(0, 1)\n",
        "# Only to numerical_transform_cols, not for timestamp, categoricals\n",
        "def transform_features(df, systemId_selected, numerical_transform_cols, print_flag=False):\n",
        "  from sklearn.preprocessing import PowerTransformer\n",
        "  #from sklearn.preprocessing import QuantileTransformer\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df[numerical_transform_cols]\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]][numerical_transform_cols]\n",
        "  # Start Transformation\n",
        "  data = df_tmp.values\n",
        "  power = PowerTransformer(method='box-cox', standardize=True)\n",
        "  data = power.fit_transform(data)\n",
        "  if print_flag:\n",
        "    print(f'*** Inside transform_features(): df_tmp.shape={df_tmp.shape}')\n",
        "    print(f'  transform_features: {power.get_params(deep=True)}')\n",
        "    print(f'  power.lambdas_: {power.lambdas_}')\n",
        "  return data, power\n",
        "\n",
        "# RUN: LabelEncoder + OneHotEncoder for categorical columns\n",
        "# return np.array oflabel encoded data and encoders\n",
        "def label_encode(df_in, systemId_selected, cols_to_encode, print_flag=False):\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df = df_in\n",
        "  else:  \n",
        "    df = df_in[df_in['systemId']==systemId_selected[0]]\n",
        "  print(f'inside label_encode: systemId={systemId_selected}, df shape={df.shape}')\n",
        "  first_col = True\n",
        "  label_encoders = []\n",
        "  my_onehot_encoders = []\n",
        "  for col in cols_to_encode:\n",
        "    label_encoder = LabelEncoder()\n",
        "    X = df[col].values\n",
        "    X = label_encoder.fit_transform(X)\n",
        "    label_encoders.append({col:label_encoder})\n",
        "    X = X.reshape(X.shape[0], 1)\n",
        "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "    X = onehot_encoder.fit_transform(X)\n",
        "    if print_flag:\n",
        "      print(f'******Inside label_encode: just after my_OneHotEncoder: col={col}, X.shape={X.shape}')\n",
        "      print(f'******Inside label_encode: just after my_OneHotEncoder: col={col}, onehot_encoder={onehot_encoder}')\n",
        "    if first_col:\n",
        "      data = X\n",
        "      #print(f'first_col={first_col}, col={col}, X.shape={X.shape}, data.shape={data.shape}')\n",
        "      first_col = False\n",
        "    else:        \n",
        "      data = np.concatenate((data, X), axis=1)\n",
        "      #print(f'first_col={first_col}, col={col}, X.shape={X.shape}, data.shape={data.shape}')\n",
        "  return data, label_encoders, my_onehot_encoders \n",
        "\n",
        "def minmax_scaler_time(df, systemId_selected, cols):\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df[cols].values\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]][cols].values\n",
        "  minmax_scaler = MinMaxScaler()\n",
        "  df_tmp = minmax_scaler.fit_transform(df_tmp)\n",
        "  return df_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geDYFuM9cMJB"
      },
      "source": [
        "Compare hists of each single systemId ('sys1' vs 'sys2', etc) and single systemId with hist of all systemIds 'All' case:\n",
        "1. each systemId has different hist patterns\n",
        "2. Hour_Sin and Hour_Cos show a pattern at certain times per hour\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8UcedkVMFac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332249cc-25d8-435b-832a-f706f5f6ba47"
      },
      "source": [
        "print(df.columns.shape, '\\n', df.columns)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18,) \n",
            " Index(['systemId', 'model_type', 'cpu_utilization', 'read_cache_miss',\n",
            "       'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput',\n",
            "       'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds',\n",
            "       'Hour_Sin', 'Hour_Cos', 'Day_Sin', 'Day_Cos', 'Week_Sin', 'Week_Cos'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4htquO_NTH9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f0d855-2fe0-46ef-ec48-2ced4af9681c"
      },
      "source": [
        "# Step 1: transform AND standarization FOR numerical_transform_cols\n",
        "# Step 1.1: transform target Y\n",
        "# MUST first use numerical_transform_cols THEN use cols_to_encode\n",
        "# MUST NOT transform timestamp_seconds !!! \n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "data_cols = []\n",
        "data = get_target_for_transform(df, SYSTEM_ID_SELECTED, target_col)\n",
        "target_transformer = PowerTransformer(method='box-cox', standardize=True)\n",
        "data = target_transformer.fit_transform(data)\n",
        "data_cols = data_cols + target_col\n",
        "\n",
        "print(f'After Y PowerTransformer, data shape={data.shape}, target_col len = {len(target_col)}, data_cols={len(data_cols)}')\n",
        "print(f'  target_transformer.get_params = : {target_transformer.get_params(deep=True)}')\n",
        "print(f'  target_transformer.lambdas_= {target_transformer.lambdas_}')\n",
        "\n",
        "# Step 1.2: transform AND standarization FOR numerical_transform_cols\n",
        "# MUST first use numerical_transform_cols THEN use cols_to_encode\n",
        "# MUST NOT transform timestamp_seconds !!! \n",
        "\n",
        "print(f'Before X numericals transformation:')\n",
        "print(f'  data shape = {data.shape}')\n",
        "print(f'  len of numerical_transform_cols = {len(numerical_transform_cols)}')\n",
        "data_new, numerical_X_transformer = transform_features(df, SYSTEM_ID_SELECTED, numerical_transform_cols)\n",
        "data_cols = data_cols + numerical_transform_cols\n",
        "data = np.concatenate((data, data_new), axis=1)\n",
        "print(f'After X numericals transformation:')\n",
        "print(f'  data shape={data.shape}')\n",
        "print(f'  data_cols len={len(data_cols)},\\n  data_cols={data_cols}')\n",
        "\n",
        "\n",
        "# process timestamp_seconds\n",
        "if USE_TIME_STAMP:\n",
        "  print(f'Before add new column {time_col}:\\n  data shape={data.shape},\\n  len time_col={len(time_col)}')\n",
        "  data_new = minmax_scaler_time(df, SYSTEM_ID_SELECTED, time_col)\n",
        "  data_cols = data_cols + time_col\n",
        "  data = np.concatenate((data, data_new), axis=1)\n",
        "  print(f'After add {time_col}:\\n  data shape={data.shape},\\n  len data_cols={len(data_cols)}')\n",
        "\n",
        "# RUN: MinMax timestamp_seconds, not StandardScaler\n",
        "# timestamp_seconds will be mapped to data[:,9] AND X[:,8]\n",
        "if USE_TIME_TRANSFORMED:\n",
        "  data_cols = data_cols + time_transformed_cols\n",
        "  data_new = minmax_scaler_time(df, SYSTEM_ID_SELECTED, time_transformed_cols)\n",
        "  print(f'Before add {len(time_transformed_cols)} columns {time_transformed_cols}:\\n  data shape={data.shape},\\n  data_new shape={data_new.shape}')\n",
        "  data = np.concatenate((data, data_new), axis=1)\n",
        "  print(f'After add time_transformed_cols:\\n  data shape={data.shape},\\n  data_cols ={data_cols}')\n",
        "\n",
        "\n",
        "# Add label encoder categorical columns (model_type only) (sysemId)\n",
        "# Note: This is only useful is model all systemIds together;\n",
        "# WARNING: only run once to avoid add the same columns more than 1 times\n",
        "\n",
        "data_new, label_encoders, my_onehot_encoders = label_encode(df, SYSTEM_ID_SELECTED, cols_to_encode)\n",
        "print(f'Before add {len(cols_to_encode)} columns {cols_to_encode}:\\n  data shape={data.shape},\\n  data_new shape={data_new.shape}')\n",
        "data = np.concatenate((data, data_new), axis=1)\n",
        "data_cols = data_cols + cols_to_encode\n",
        "\n",
        "print(f'After concatenate:\\n  data shape={data.shape}')\n",
        "print(f'  data_cols len={len(data_cols)},\\n  data_cols={data_cols}')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After Y PowerTransformer, data shape=(7926, 1), target_col len = 1, data_cols=1\n",
            "  target_transformer.get_params = : {'copy': True, 'method': 'box-cox', 'standardize': True}\n",
            "  target_transformer.lambdas_= [0.07711959]\n",
            "Before X numericals transformation:\n",
            "  data shape = (7926, 1)\n",
            "  len of numerical_transform_cols = 8\n",
            "After X numericals transformation:\n",
            "  data shape=(7926, 9)\n",
            "  data_cols len=9,\n",
            "  data_cols=['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz']\n",
            "Before add new column ['timestamp_seconds']:\n",
            "  data shape=(7926, 9),\n",
            "  len time_col=1\n",
            "After add ['timestamp_seconds']:\n",
            "  data shape=(7926, 10),\n",
            "  len data_cols=10\n",
            "Before add 6 columns ['Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos']:\n",
            "  data shape=(7926, 10),\n",
            "  data_new shape=(7926, 6)\n",
            "After add time_transformed_cols:\n",
            "  data shape=(7926, 16),\n",
            "  data_cols =['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos']\n",
            "inside label_encode: systemId=['sys1'], df shape=(7926, 18)\n",
            "Before add 2 columns ['systemId', 'model_type']:\n",
            "  data shape=(7926, 16),\n",
            "  data_new shape=(7926, 2)\n",
            "After concatenate:\n",
            "  data shape=(7926, 18)\n",
            "  data_cols len=18,\n",
            "  data_cols=['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos', 'systemId', 'model_type']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SoypBGi0658",
        "outputId": "707d9aff-d57d-48b8-df77-509e851ed036"
      },
      "source": [
        "print(data.shape, len(data_cols), data_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7926, 18) 18 ['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos', 'systemId', 'model_type']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lr_2nEAkkP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "da762d0d-f59e-4bdd-8e47-447c97fd6285"
      },
      "source": [
        "print(f'After add {time_col}:\\n  data shape={data.shape},\\n  len data_cols={len(data_cols)}')\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(data[:, TIMESTAMP_INDEX_BEFORE_FS])\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(data[:, TIMESTAMP_INDEX_BEFORE_FS], data[:, 0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After add ['timestamp_seconds']:\n",
            "  data shape=(7926, 18),\n",
            "  len data_cols=18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc5f2fe1650>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-tXQCqCxF4b"
      },
      "source": [
        "# check time transformations are all right\n",
        "plt.figure()\n",
        "index_to_plots = [1,3,5,7,8]\n",
        "L = len(index_to_plots)\n",
        "for k in range(L):\n",
        "  plt.subplot(L,1,k+1)\n",
        "  plt.plot(data[:, TIMESTAMP_INDEX_BEFORE_FS], data[:, TIMESTAMP_INDEX_BEFORE_FS + index_to_plots[k]],)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeNDWMD6jyqv"
      },
      "source": [
        "# Compare hist before/after transformation/scaling \n",
        "# Before transformation: hist\n",
        "title_str = 'Before transformation!'\n",
        "plot_df_hist(df, SYSTEM_ID_SELECTED, title_str, df.columns, 30)\n",
        "#NOTE: Hour_Sin AND Hour_Cos have only 7 distinct bins at [0, 30, 60, 90, -30, -60, -90] degress as \n",
        "# as sampling perid=5 minutes, thus 2pi*5min/60min=pi/6=30degree\n",
        "\n",
        "# After transformation: hist\n",
        "title_str = 'After transformation!'\n",
        "data_df = pd.DataFrame(data, columns=data_cols)\n",
        "plot_df_hist(data_df, ['All'], title_str, data_df.columns, 30)\n",
        "del data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayriUf62sfFV"
      },
      "source": [
        "Feature selection:\n",
        "1. correlation based\n",
        "2. L1 norm\n",
        "3. p-value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daCEstTKvKjS",
        "outputId": "d5ccb21f-2d8e-4d27-fd9d-a2762dc9caea"
      },
      "source": [
        "# set X, Y, x_cols\n",
        "X = data[:, X_FIRST_INDEX_DATA:]\n",
        "Y = data[:, Y_INDEX_DATA]\n",
        "data_cols\n",
        "x_cols = data_cols[1:]\n",
        "\n",
        "print(f' data_cols = {data_cols}, \\n x_cols = {x_cols}' )\n",
        "print(f' data.shape = {data.shape}, len(data_cols) = {len(data_cols)}')\n",
        "print(f' X.shape = {X.shape}, Y.shape = {Y.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " data_cols = ['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos', 'systemId', 'model_type'], \n",
            " x_cols = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos', 'systemId', 'model_type']\n",
            " data.shape = (7926, 18), len(data_cols) = 18\n",
            " X.shape = (7926, 17), Y.shape = (7926,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mXegL8seAG"
      },
      "source": [
        "# RUN: feature selection based on correlation  \n",
        "# NOTE: this is done separately for each of systemId, not for all systemIds altogether\n",
        "#label encoder for model\n",
        "def select_feature_by_correlation(data, data_cols, target_col, corr_threshold):\n",
        "  df = pd.DataFrame(data, columns=data_cols)\n",
        "  #del df[target_col[0]]\n",
        "  corr = df.corr()\n",
        "  columns = np.full((corr.shape[0],), True, dtype=bool)\n",
        "  for i in range(corr.shape[0]):\n",
        "    for j in range(i+1, corr.shape[0]):\n",
        "      if corr.iloc[i,j] >= corr_threshold:\n",
        "        columns[j] = False\n",
        "  selected_columns = df.columns[columns]\n",
        "  removed_columns = [x for x in df.columns if x not in selected_columns]\n",
        "\n",
        "  print(f'df shape={df.shape}; corr shape={corr.shape};')\n",
        "  print(f'df.columns={df.columns}')\n",
        "  print(f'columns={columns}')\n",
        "  print(f'selected_columns={selected_columns}')\n",
        "  print(f'removed_columns={removed_columns}')\n",
        "  return selected_columns, removed_columns, corr\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YeRXt7Ewd0c"
      },
      "source": [
        "# RUN: feature selection based on correlation  \n",
        "CORR_THRESHOLD_FEATURE_SELECTION = 0.8;\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "#corr_X\n",
        "selected_columns, removed_columns, corr_X = select_feature_by_correlation(X, x_cols, target_col, CORR_THRESHOLD_FEATURE_SELECTION)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e2vpiv_xEW7"
      },
      "source": [
        "# corr_data\n",
        "_, _, corr_data = select_feature_by_correlation(data, data_cols, target_col, CORR_THRESHOLD_FEATURE_SELECTION)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5oT80EIxvV8"
      },
      "source": [
        "corr_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T93dvZn7a0u"
      },
      "source": [
        "# plot 'read_throughput', 'read_cache_miss'\n",
        "cols_correlated = ['read_throughput', 'read_cache_miss', 'read_iops', 'write_iops']\n",
        "cols_correlated_index = [data_cols.index(x) for x in cols_correlated]\n",
        "\n",
        "print(len(data_cols), data.shape)\n",
        "print(cols_correlated_index, data_cols)\n",
        "plt.figure()\n",
        "plt.plot(data[:, cols_correlated_index[0]], data[:, cols_correlated_index[1]], '+')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(data[:, cols_correlated_index[0]], data[:, cols_correlated_index[2]], '+')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(data[:, cols_correlated_index[0]], data[:, cols_correlated_index[3]], '+')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(data[:, cols_correlated_index[2]], data[:, cols_correlated_index[3]], '+')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SauEIOzh6PbF"
      },
      "source": [
        "import sklearn\n",
        "sorted(sklearn.metrics.SCORERS.keys())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HygDlXOKAXK2"
      },
      "source": [
        "# make a regression prediction with an RFE pipeline\n",
        "# Observation: Features are selected almost according to their correlation with target\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "# create pipeline\n",
        "for num_features in range(2,17):\n",
        "  rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=num_features)\n",
        "  #model = DecisionTreeRegressor()\n",
        "  #pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "  # fit the model on all available data\n",
        "  #pipeline.fit(X, Y)\n",
        "  rfe.fit(X, Y)\n",
        "  scores = rfe.score(X, Y)\n",
        "  selected_features = rfe.get_support(indices=True)\n",
        "  print(num_features, selected_features, scores)\n",
        "  selected_feature_str = [x_cols[x] for x in selected_features]\n",
        "  print(f'  {selected_feature_str}')\n",
        "  print(f\"  {corr_data.loc[selected_feature_str, target_col[0]]}\")\n",
        "\n",
        "# make a prediction for one example\n",
        "#data = [[-2.02220122,0.31563495,0.82797464,-0.30620401,0.16003707,-1.44411381,0.87616892,-0.50446586,0.23009474,0.76201118]]\n",
        "#yhat = pipeline.predict(data)\n",
        "#print('Predicted: %.3f' % (yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEpsH9rDHwN5",
        "outputId": "910bf7ac-cb34-4005-d3cd-337deec9f937"
      },
      "source": [
        "corr['cpu_utilization']\n",
        "corr.loc[['read_iops', 'read_throughput'], 'cpu_utilization']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "read_iops          0.388049\n",
              "read_throughput    0.522006\n",
              "Name: cpu_utilization, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLlteBO4B5Dm",
        "outputId": "0d769545-1748-42e2-987b-06b9cf5d61d3"
      },
      "source": [
        "print(col_new.shape)\n",
        "print(rfe.get_support(indices=False))\n",
        "print(rfe.get_support(indices=True))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7926, 5)\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kimaSZmqwCgN"
      },
      "source": [
        "# Start RFE feature selection; \n",
        "# Input: X, Y, num_features_to_select\n",
        "\n",
        "num_features_to_select = [12,13]\n",
        "# evaluate RFE for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(num_features_to_select[0], num_features_to_select[1]):\n",
        "\t\trfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=i)\n",
        "\t\tmodel = DecisionTreeRegressor()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "#>>> pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "  #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  kfold = KFold(n_splits = NUM_SPLITS) # shuffle=False\n",
        "  scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', \n",
        "                           cv=kfold, n_jobs=-1, error_score='raise')\n",
        "  return scores\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "  scores = evaluate_model(model, X, Y)\n",
        "  results.append(scores)\n",
        "  names.append(name)\n",
        "  print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "  #print(model.support_, model.ranking_)\n",
        "  print(model)\n",
        "# plot model performance for comparison\n",
        "plt.boxplot(results, labels=names, showmeans=True)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmwqmTSlmWkp"
      },
      "source": [
        "Observation:\n",
        "1. read_throughput and read_cache_miss are highly correlated (0.862791);\n",
        "2. model_type and systemId are unrelated in case of single case systemId\n",
        "3. timestamps not contribute much\n",
        "4. transfomred times have some correlation with a few columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfSUUplsnQ1Y",
        "outputId": "b2de4660-a699-4165-851c-d20a937bc888"
      },
      "source": [
        "removed_columns = removed_columns + ['model_type', 'systemId']\n",
        "removed_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['read_throughput', 'model_type', 'systemId']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv55QQPZrs-m"
      },
      "source": [
        "def remove_data_columns(data, data_cols, removed_columns):\n",
        "  data_index_remove = [data_cols.index(x) for x in removed_columns]\n",
        "  print(f'data_index_remove = {data_index_remove}')\n",
        "  data = np.delete(data, data_index_remove, axis=1)\n",
        "  data_cols_updated = [ x for x in data_cols if x not in removed_columns]\n",
        "  print(data.shape, len(data_cols_updated), data_cols_updated)\n",
        "  return data_cols_updated, data  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETtdxZbwoRG2",
        "outputId": "b01ce2e4-049b-4d3d-b645-4350dc62c84c"
      },
      "source": [
        "# WARNING: only run this ONCE\n",
        "data_cols, data = remove_data_columns(data, data_cols, removed_columns)\n",
        "TIMESTAMP_INDEX_AFTER_FS = data_cols.index('timestamp_seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_index_remove = [5, 17, 16]\n",
            "(7926, 15) 15 ['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'write_throughput', 'read_iosz', 'write_iosz', 'timestamp_seconds', 'Week_Sin', 'Week_Cos', 'Day_Sin', 'Day_Cos', 'Hour_Sin', 'Hour_Cos']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkM4QyArtcnD",
        "outputId": "b5544f38-cb5a-4e02-de75-fc476a718c5f"
      },
      "source": [
        "# After all feature selections are done: get timestamp index in data\n",
        "TIMESTAMP_INDEX_AFTER_FS = data_cols.index('timestamp_seconds')\n",
        "print(data.shape, len(data_cols) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7926, 15) 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5DjStPS4wY2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA33dDYjgnCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dd6e526-c7fd-4db2-d78f-90a1900a7182"
      },
      "source": [
        "NUM_SPLITS = 10\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Regression\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X = data[:, X_FIRST_INDEX_DATA:]\n",
        "Y = data[:, Y_INDEX_DATA]\n",
        "\n",
        "# define base model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(18, input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\treturn model\n",
        "  \n",
        "# Step: evaluate model with standardized dataset\n",
        "estimators = []\n",
        "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose=1)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "kfold = KFold(n_splits = NUM_SPLITS) # shuffle=False\n",
        "#results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
        "print(f'X shape={X.shape}, Y shape = {Y.shape}')\n",
        "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
        "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "print(results)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "# TRY this also\n",
        "#from sklearn import linear_model\n",
        "\n",
        "# cross_val_predict returns an array of the same size as `y` where each entry\n",
        "# is a prediction obtained by cross validation:\n",
        "predicted = cross_val_predict(pipeline, X, Y, cv=kfold)\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(Y, predicted)\n",
        "ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
        "ax.set_xlabel('Measured')\n",
        "ax.set_ylabel('Predicted')\n",
        "ax.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape=(7926, 17), Y shape = (7926,)\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9987\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4775\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0738\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0591\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0579\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0565\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0549\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0537\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0556\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0545\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0547\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0557\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0545\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0536\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0526\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0536\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0518\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0531\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0527\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0545\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0511\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9863\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.4950\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0658\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0579\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0559\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0564\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0546\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0546\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0525\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0569\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0507\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0543\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0504\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0474\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0464\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0476\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0459\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0468\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0441\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0429\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9768\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.4866\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0627\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0524\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0553\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0505\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0499\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0492\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0502\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0496\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0497\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0471\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0507\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0470\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0487\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0458\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0424\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0413\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0573\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9674\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.7640\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.1175\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0596\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0576\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0552\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0559\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0567\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0542\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0522\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0520\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0509\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0489\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0491\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0466\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0478\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0461\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0455\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0414\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 1.0000\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.5176\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0675\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0573\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0547\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0563\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0555\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0550\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0561\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0552\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0556\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0524\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0526\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0497\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0511\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0477\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0484\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0467\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0480\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0467\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0412\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9556\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.5002\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0831\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0596\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0551\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0545\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0514\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0508\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0507\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0475\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0480\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0487\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0441\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0455\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0453\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0457\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0415\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9908\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6286\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0948\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0600\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0555\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0546\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0549\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0546\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0542\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0555\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0563\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0571\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0549\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0537\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0549\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0531\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0558\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0542\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0525\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0543\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0504\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 1.0194\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.6380\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0836\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0566\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0544\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0544\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0547\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0531\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0523\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0553\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0552\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0549\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0567\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0543\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0536\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0532\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0547\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0532\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0521\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0528\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0476\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9733\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6978\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0801\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0592\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0541\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0533\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0538\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0535\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0518\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0506\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0505\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0483\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0473\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0470\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0452\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0579\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9549\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.4875\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0830\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0552\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0573\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0545\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0525\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0521\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0494\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0455\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0477\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0465\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0450\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0462\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0430\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0600\n",
            "Standardized: -0.05 (0.01) MSE\n",
            "[-0.05108608 -0.0429323  -0.05727289 -0.04138578 -0.04124396 -0.0415484\n",
            " -0.0503659  -0.04757507 -0.05793243 -0.05996271]\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9971\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.6061\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0817\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0574\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0563\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0551\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0555\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0524\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0515\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0513\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0516\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0550\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0510\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0493\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0514\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0511\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0497\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0521\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0498\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.9698\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.5180\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0674\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0538\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0503\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0488\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0465\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0475\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0469\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0458\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0464\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0462\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0460\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0440\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 1.0031\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5093\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0990\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0570\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0541\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0515\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0517\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0516\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0517\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0503\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0526\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0512\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0505\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0506\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0528\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0512\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0504\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0506\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0482\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0461\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9957\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5142\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0956\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0553\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0519\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0494\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0487\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0460\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0491\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0470\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0464\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0487\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0464\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0433\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.9943\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.7089\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1317\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0560\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0549\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0543\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0564\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0551\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0535\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0528\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0567\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0554\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0543\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0522\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0535\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0541\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0530\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0523\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0510\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 1ms/step - loss: 0.9883\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7279\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4089\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.3751\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3020\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.2866\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.2622\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2325\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2199\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2002\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1828\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1717\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.1656\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1570\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1449\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.1320\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1256\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.1198\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1123\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1070\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.9980\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6163\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0557\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0562\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0545\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0530\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0507\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0482\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0489\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0464\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0460\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0456\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0443\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 1.0217\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5449\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0766\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0552\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0550\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0556\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0562\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0553\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0549\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0548\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0529\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0544\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0520\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0512\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0518\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0502\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0511\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0494\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0480\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0477\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9936\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6136\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.1188\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0581\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0559\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0548\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0529\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0520\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0550\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0515\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0514\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0549\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0526\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0510\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0510\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0532\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0511\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0503\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0502\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0508\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "72/72 [==============================] - 1s 2ms/step - loss: 0.9757\n",
            "Epoch 2/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.6223\n",
            "Epoch 3/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0661\n",
            "Epoch 4/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0536\n",
            "Epoch 5/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0553\n",
            "Epoch 6/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0537\n",
            "Epoch 7/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0510\n",
            "Epoch 8/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0492\n",
            "Epoch 9/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0491\n",
            "Epoch 10/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0468\n",
            "Epoch 11/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0470\n",
            "Epoch 12/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0456\n",
            "Epoch 13/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0462\n",
            "Epoch 14/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0431\n",
            "Epoch 15/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0432\n",
            "Epoch 16/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 17/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 18/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0427\n",
            "Epoch 19/20\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "Epoch 20/20\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.0450\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NggJ8k183MU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1sZLY0RwFuE"
      },
      "source": [
        "print(data.shape, X.shape, Y.shape, type(X))\n",
        "plt.plot(data[:, TIMESTAMP_INDEX_BEFORE_FS], label='TIMESTAMP_INDEX_BEFORE_FS')\n",
        "plt.plot(data[:, TIMESTAMP_INDEX_AFTER_FS], label='TIMESTAMP_INDEX_AFTER_FS')\n",
        "ax=plt.gca()\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWzm1AQh-jq-"
      },
      "source": [
        "print(data.shape, X.shape, Y.shape, type(X))\n",
        "plt.plot(X[:, TIME_INDEX_IN_X-1], label='TIME_INDEX_IN_X-1')\n",
        "plt.plot(X[:, TIME_INDEX_IN_X], label='TIME_INDEX_IN_X')\n",
        "ax=plt.gca()\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxCsofhfhijW"
      },
      "source": [
        "# plot against time IN transformed/scaled version\n",
        "def plot_prediction_time(start, stop, X, Y, predicted):\n",
        "  num_cols = 3\n",
        "  plt.subplot(num_cols, 1, 1)\n",
        "  plt.plot(X[start:stop, TIMESTAMP_INDEX_AFTER_FS-1], Y[start:stop], 'b-+', label='rea target')\n",
        "  #plt.plot(X[start:stop, TIMESTAMP_INDEX_AFTER_FS-1], ( predicted[start:stop]), 'g-o', label='predicted target')\n",
        "  plt.plot(X[start:stop, TIMESTAMP_INDEX_AFTER_FS-1], (Y[start:stop] - predicted[start:stop]), 'g-o', label='error')\n",
        "  plt.ylabel('scaled target')\n",
        "  plt.xlabel('scaled time')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(num_cols, 1, 2)\n",
        "  plt.plot(data[start:stop, TIMESTAMP_INDEX_AFTER_FS], (Y[start:stop] - predicted[start:stop])/(Y[start:stop]), 'r-*', label='error/real')\n",
        "  plt.ylim(0, 1)\n",
        "  plt.ylabel('scaled target')\n",
        "  plt.xlabel('scaled time')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(num_cols, 1, 3)\n",
        "  #plt.plot(X[start:stop, TIMESTAMP_INDEX_AFTER_FS-1])\n",
        "  plt.hist((Y[start:stop] - predicted[start:stop])/(Y[start:stop]), bins=100)\n",
        "  plt.ylabel('scaled time')\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(22.5, num_cols*3)\n",
        "\n",
        "\n",
        "# Get orignal target w/o transformation from df\n",
        "def get_target(df, systemId_selected, numerical_transform_cols):\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df[numerical_transform_cols]\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]][numerical_transform_cols]\n",
        "  return df_tmp.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBkHs8Gdxp6Y"
      },
      "source": [
        "TIME_INDEX_IN_X = TIMESTAMP_INDEX_AFTER_FS - 1 # minus 1 to count target at index 0\n",
        "start= 1000 #int(0*24*60/5)\n",
        "stop = 1111 #len(Y) #int(1*24*60/5)\n",
        "plot_prediction_time(start, stop, X, Y, predicted)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmJANDYhGtX8"
      },
      "source": [
        "start=100; stop=110\n",
        "print(Y[start:stop], '\\n',predicted[start:stop], '\\n',\n",
        "      Y[start:stop]- predicted[start:stop], '\\n', (Y[start:stop]- predicted[start:stop])/Y[start:stop])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGHpeYz6GIA3"
      },
      "source": [
        "plt.plot(Y, predicted, '+')\n",
        "plt.grid()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(22.5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7edDXw2TxBV1"
      },
      "source": [
        "y_real = get_target(df, SYSTEM_ID_SELECTED, 'cpu_utilization' )\n",
        "\n",
        "# RUN: inverse_transform of predicted target \n",
        "y_hat = target_transformer.inverse_transform( predicted.reshape(predicted.shape[0], 1) )\n",
        "print(predicted.shape, y_hat.shape, type(y_hat))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDkxtKHexa_C"
      },
      "source": [
        "# RUN: inverse_transform TRUE target transformed\n",
        "y_real_inverse_transfomred = target_transformer.inverse_transform( Y.reshape(Y.shape[0], 1) )\n",
        "print(Y.shape, y_real_inverse_transfomred.shape, type(y_real_inverse_transfomred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdxBPl5XzBQ4"
      },
      "source": [
        "plt.plot(y_real, y_real_inverse_transfomred, '+')\n",
        "plt.grid()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(22.5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkFDk0ASyHea"
      },
      "source": [
        "plt.plot(y_real_inverse_transfomred, y_hat, '+')\n",
        "plt.grid()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(22.5, 5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iKuQORI0GEQ"
      },
      "source": [
        "# TODO: get real time in timedate\n",
        "#plot inverse transformed y_hat against time\n",
        "fig, ax = plt.subplots()\n",
        "start= int(0*24*60/5)\n",
        "stop = int(0.2*24*60/5)\n",
        "\n",
        "ax.plot(X[:, TIME_INDEX_IN_X][start:stop], y_real[start:stop], 'b-+', label='real')\n",
        "ax.plot(X[:, TIME_INDEX_IN_X][start:stop], y_hat[:, 0][start:stop], 'g-o', label='predicted')\n",
        "ax.set_xlabel('scaled time')\n",
        "ax.set_ylabel('Predicted')\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(22.5, 3)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgtNPUf0xp-x"
      },
      "source": [
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_real, y_hat[:, 0])\n",
        "ax.plot([y_real.min(), y_real.max()], [y_real.min(), y_real.max()], 'k--', lw=4)\n",
        "ax.set_xlabel('Measured')\n",
        "ax.set_ylabel('Predicted')\n",
        "ax.grid()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 5)\n",
        "plt.show()\n",
        "predicted.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcgEv1n7xqD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyVV3Z8pvqgK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMZkqYdVz_Gu"
      },
      "source": [
        "Finished regression here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqOQt7XBLb-s"
      },
      "source": [
        "# Run this after Standardarization\n",
        "# Add nonlinear transformation of features\n",
        "df['rw_cache_miss_ratio'] = df['read_cache_miss'] / df['write_cache_miss']\n",
        "df['rw_iops_ratio'] = df['read_iops'] / df['write_iops']\n",
        "df['rw_throughput_ratio'] = df['read_throughput'] / df['write_throughput']\n",
        "df['rw_iosz_ratio'] = df['read_iosz'] / df['write_iosz']\n",
        "\n",
        "df['rw_cache_miss_diff'] = df['read_cache_miss'] - df['write_cache_miss']\n",
        "df['rw_iops_diff'] = df['read_iops'] - df['write_iops']\n",
        "df['rw_throughput_diff'] = df['read_throughput'] - df['write_throughput']\n",
        "df['rw_iosz_diff'] = df['read_iosz'] - df['write_iosz']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vjiyYZ1U7x7"
      },
      "source": [
        "# remove cols_remove from cols;\n",
        "# divide cols into array of lists of size W \n",
        "def split_columns(cols, cols_remove, W):\n",
        "  for col in cols_remove:\n",
        "    cols.remove(col)\n",
        "  L = len(cols)\n",
        "  R = int(L/W)\n",
        "  x1 = list(np.array(cols[:R*W]).reshape(R,W))\n",
        "  x2 = cols[R*W:]\n",
        "  x1.append(x2)\n",
        "  return x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM0rK8fcJAC4"
      },
      "source": [
        "# RUN: pairplotr VERY SLOW for larger number of features! !!\n",
        "def pairplot(df, systemId_selected, cols, title_str):\n",
        "  if len(systemId_selected)>0:\n",
        "    df = df[df['systemId']==systemId_selected]\n",
        "  sns.pairplot(df[cols], corner=True)\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(15.5, 3*2)\n",
        "  fig.suptitle(f'{title_str}, systemId {systemId_selected[0]}')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHKHE7h5Z91t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKyG7xdKHobv"
      },
      "source": [
        "systemId = 'sys1'\n",
        "cols = list(df.columns.values)\n",
        "cols_remove = ['timestamp_seconds', 'systemId', 'model_type']\n",
        "W = 4\n",
        "cols_groups = split_columns(cols, cols_remove, W)\n",
        "print(f'cols_groups={cols_groups}')\n",
        "title_str = 'Before Transformation'\n",
        "\n",
        "for col_subset in cols_groups:\n",
        "  pairplot(df, systemId, col_subset, title_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmqsItbZ_bCR"
      },
      "source": [
        "print(f' data.shape={data.shape}, data_cols len={len(data_cols)}\\n data_cols={data_cols}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_jGhaNqH-FO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj6UjlSoAuos"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_PLsg9bhyfx"
      },
      "source": [
        "def plot_corr(df, systemId_selected):\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]]\n",
        "  sns.set_theme(style=\"white\")\n",
        "  # Compute the correlation matrix\n",
        "  corr = df_tmp.corr()\n",
        "  # Generate a mask for the upper triangle\n",
        "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "  # Set up the matplotlib figure\n",
        "  f, ax = plt.subplots(figsize=(15, 9))\n",
        "\n",
        "  # Generate a custom diverging colormap\n",
        "  cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "  # Draw the heatmap with the mask and correct aspect ratio\n",
        "  sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "  f.suptitle(f'systemId {systemId_selected[0]}')\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSgHqE5LXMR"
      },
      "source": [
        "plot_corr(df, systemId_selected)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QquxwQdyOfVe"
      },
      "source": [
        "**Observation** \n",
        "After comparison Correlation plots of two cases:\n",
        "-- Case_SINGLE: Only extract a single systemId (here 'sys1') case; \n",
        "-- Case_ALL:  Use all systemIds as a whole;\n",
        "\n",
        "Conclusion:\n",
        "1. timestamp_seconds has low correlation with all the rest features; and is less useful directly;\n",
        "2. Day_Cos and Day_Sin have good correlation with a few columns and shall help prediction;\n",
        "\n",
        "\n",
        "Case_SINGLE clearly exposes a larger nuber of columns having high correlations with the target 'cpu_utilization' than  that of Case_ALL. \n",
        "\n",
        "1.1 columns having good correlation with 'cpu_utilization':\n",
        "Case_SINGLE: ['write_throughput', 'write_iops', 'read_cache_miss', 'read_throughput', 'read_iops', 'write_cache_miss']\n",
        "\n",
        "Case_ALL: ['read_throughput', 'read_cache_miss'] \n",
        "['write_cache_miss',  'read_iops', 'write_throughput', 'write_iosz' ]\n",
        "\n",
        "1.1 columns having good correlation with Day_sin:  \n",
        "Case_SINGLE ['write_cache_miss', 'read_iops', 'write_iosz' ]\n",
        "Case_ALL: None\n",
        "\n",
        "1.2 Day_Cos has good correlation with 2 columns:\n",
        "Case_SINGLE: ['write_iops', 'read_iosz']\n",
        "Case_ALL: None\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3HYKew1UHfa"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArbVaWPQL-Dm"
      },
      "source": [
        "plot_corr(df, systemId_selected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFCeFr9XoPbA"
      },
      "source": [
        "# normalize, average, and plot\n",
        "\n",
        "def plot_columns_average(df, AVERAGE_METHOD, Window_Length):\n",
        "  df1 = df[df['systemId']=='sys1']\n",
        "\n",
        "  start_hour = 24*1+15;\n",
        "  interval_hour= 24*20 + 10\n",
        "  start = int(start_hour*hour/(5*60))\n",
        "  stop = int((start_hour + interval_hour)*hour/(5*60))\n",
        "\n",
        "  #x = df1['timestamp_seconds']\n",
        "  df1['iops_rw_diff'] = df1['read_iops'] - df1['write_iops']\n",
        "  df1['iops_rw_ratio'] = df1['read_iops']/df1['write_iops']\n",
        "\n",
        "  df1['throughput_rw_diff'] = df1['read_throughput'] - df1['write_throughput']\n",
        "  df1['throughput_rw_ratio'] = df1['read_throughput'] / df1['write_throughput']\n",
        "\n",
        "  cols = ['write_cache_miss',  'read_iops', 'write_iosz', 'cpu_utilization', 'read_cache_miss', \n",
        "          'read_iosz', 'read_throughput', 'write_throughput', 'throughput_rw_diff', 'throughput_rw_ratio',\n",
        "          'write_iops', 'iops_rw_diff', 'iops_rw_ratio', 'Day_Sin', 'Week_Sin']#, 'Hour_Sin']\n",
        "\n",
        "  ### moving average and standarization\n",
        "  cols_to_avg = ['cpu_utilization', 'read_cache_miss', 'write_cache_miss',\n",
        "                'read_iosz', 'write_iosz', 'read_throughput', 'write_throughput', 'read_iops',\n",
        "          'write_iops','throughput_rw_diff', 'throughput_rw_ratio', 'iops_rw_diff', 'iops_rw_ratio']\n",
        "\n",
        "  for f in cols_to_avg:\n",
        "    if AVERAGE_METHOD == 'rolling_moving_average':\n",
        "      df1[f] = df1[f].rolling(window=Window_Length).mean()\n",
        "    elif AVERAGE_METHOD == 'exponential_moving_average':\n",
        "      df1[f] = df1[f].ewm(span=Window_Length, adjust=False).mean()\n",
        "    elif AVERAGE_METHOD == 'cumulative_average': \n",
        "      df1[f] = df1[f].expanding(min_periods=Window_Length, adjust=False).mean()\n",
        "    else:\n",
        "      raise ValueError(f'AVERAGE_METHOD ={AVERAGE_METHOD} is not implemented!')\n",
        "        \n",
        "  cols_normalization = ['cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iosz', 'write_iosz', \n",
        "                        'read_throughput', 'write_throughput', 'read_iops',\n",
        "          'write_iops', 'throughput_rw_diff', 'throughput_rw_ratio', 'iops_rw_diff', 'iops_rw_ratio']\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  autoscaler = StandardScaler()\n",
        "  df1.loc[:, cols_normalization] = autoscaler.fit_transform(df1.loc[:, cols_normalization])\n",
        "\n",
        "  x = df1['datetime']\n",
        "  linepattern = '-+'\n",
        "  fig = 1\n",
        "  num_cols = len(cols)\n",
        "  for f in cols:\n",
        "    y = df1[f]\n",
        "    plt.subplot(num_cols, 1, fig)\n",
        "    plt.plot(x[start:stop], y[start:stop], linepattern)\n",
        "    if f == 'write_iops' or f=='read_iosz':\n",
        "      plt.plot(x[start:stop], df1['Day_Cos'][start-60:stop-60], 'g-o')\n",
        "    else:\n",
        "      plt.plot(x[start:stop], df1['Day_Sin'][start-60:stop-60], 'g-o')\n",
        "\n",
        "    #plt.plot(x[start:stop], df1['Day_Cos'][start:stop], 'y-')\n",
        "    plt.ylabel(f)\n",
        "    fig= fig+1\n",
        "    plt.grid(True)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(22.5, num_cols*3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKmVk9usLmrc"
      },
      "source": [
        "# most sampling periods are 5 min, so window in mins is Window_Length*5 mins\n",
        "# when Window_Length = int(2*60/5) in samples, it is in time interval of 120min=2hr\n",
        "Window_Length = int(2*60/5) \n",
        "\n",
        "AVERAGE_METHOD_LIST = ['rolling_moving_average', 'exponential_moving_average', 'cumulative_average']\n",
        "AVERAGE_METHOD = AVERAGE_METHOD_LIST[1] \n",
        "plot_columns_average(df, AVERAGE_METHOD, Window_Length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p0hETXoVx8X"
      },
      "source": [
        "# check outliers; conclusion: no apparent outliers\n",
        "df_stat = df.describe().T\n",
        "df_stat['50% to 75%'] = (df_stat['50%']/df_stat['75%'])\n",
        "df_stat['max to 75%'] = (df_stat['max']/df_stat['75%'])\n",
        "df_stat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oJIeiO45BHR"
      },
      "source": [
        "print(f\" df.shape={df.shape},\\n df.columns={df.columns}\")\n",
        "sysIDs = np.unique(df['systemId'])\n",
        "print(f\" sysIDs shape={sysIDs.shape},\\n sysIDs={sysIDs}\")\n",
        "model_types = np.unique(df['model_type'])\n",
        "print(f\" model_types shape={model_types.shape}, model_types ={model_types}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrv845LJCK4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbCZIVV2HgBW"
      },
      "source": [
        "print((np.unique(df['model_type'])))\n",
        "for sysId in np.unique(df['systemId']):\n",
        "  data = df[df['systemId']==sysId]\n",
        "  x = np.unique(data['model_type'])\n",
        "  print(f'sysId={sysId}, {x}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLTZZghjAi3Y"
      },
      "source": [
        "# GANG WANG\n",
        "# RUN this: select feature based on p-value\n",
        "\n",
        "systemId = 'sys1'\n",
        "data = df[df['systemId']==systemId]\n",
        "print(np.unique(data['model_type'])\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns_to_scale=['timestamp_seconds', 'cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz']\n",
        "autoscaler = StandardScaler()\n",
        "data[columns_to_scale] = autoscaler.fit_transform(data[columns_to_scale])\n",
        "\n",
        "y_column = ['cpu_utilization']; \n",
        "x_columns = ['timestamp_seconds', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz'] #, 'datetime']\n",
        "\n",
        "x_in = data[x_columns].values\n",
        "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "label_encoder2 = LabelEncoder()\n",
        "data['model_type'] = label_encoder2.fit_transform(data['model_type'])\n",
        "feature = data['model_type'].values\n",
        "print(\"feature shape BEFORE reshape:\", feature.shape)\n",
        "feature = feature.reshape(feature.shape[0], 1)\n",
        "print(\"feature shape AFTER reshape:\", feature.shape)\n",
        "\n",
        "print(\"x_in shape BEFORE one-hot-encoder:\", x_in.shape)\n",
        "\n",
        "feature = onehot_encoder.fit_transform(feature)\n",
        "print(f'feature shape={feature.shape}')\n",
        "x_in = np.concatenate((x_in, feature), axis=1)\n",
        "print(\"x_in shape AFTER one-hot-encoder: : \", x_in.shape)\n",
        "\n",
        "\n",
        "y_in = data[y_column].values\n",
        "selected_columns = ['timestamp_seconds', 'read_cache_miss', 'write_cache_miss', 'read_iops',\n",
        "                    'write_iops', 'read_throughput', 'write_throughput', 'read_iosz',\n",
        "                    'write_iosz', 'model_type'] #, 'datetime']\n",
        "\n",
        "import statsmodels.api as sm\n",
        "def backwardElimination(x, Y, sl, columns):\n",
        "    print(f'x={x[:2,:]}')\n",
        "    print(f'Y={Y[:2]}')\n",
        "    print(f'len(x[0]) = {len(x[0])}')\n",
        "    print(f'x shape = {x.shape}')\n",
        "\n",
        "    numVars = len(x[0])\n",
        "    for i in range(0, numVars):\n",
        "        regressor_OLS = sm.OLS(Y, x).fit()\n",
        "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
        "        if maxVar > sl:\n",
        "            for j in range(0, numVars - i):\n",
        "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
        "                    x = np.delete(x, j, 1)\n",
        "                    columns = np.delete(columns, j)\n",
        "        print(f'**** backwardElimination i={i}, p-values={regressor_OLS.pvalues}')\n",
        "        print(f'inside loop: x shape = {x.shape}')\n",
        "                    \n",
        "    print(regressor_OLS.summary())\n",
        "    return x, columns\n",
        "\n",
        "SL = 0.05\n",
        "data_modeled, selected_columns = backwardElimination(x_in, y_in, SL, selected_columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxyNL1tpAl7w"
      },
      "source": [
        "def old_OneHotEncoder():\n",
        "  systemId = 'sys1'\n",
        "  data = df[df['systemId']==systemId]\n",
        "  print(np.unique(data['model_type'])\n",
        "\n",
        "  columns_to_scale=['timestamp_seconds', 'cpu_utilization', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz', 'write_iosz']\n",
        "  autoscaler = StandardScaler()\n",
        "  data[columns_to_scale] = autoscaler.fit_transform(data[columns_to_scale])\n",
        "\n",
        "  y_column = ['cpu_utilization']; \n",
        "  x_columns = ['timestamp_seconds', 'read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz'] #, 'datetime']\n",
        "\n",
        "  x_in = data[x_columns].values\n",
        "  onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "  label_encoder2 = LabelEncoder()\n",
        "  data['model_type'] = label_encoder2.fit_transform(data['model_type'])\n",
        "  feature = data['model_type'].values\n",
        "  print(\"feature shape BEFORE reshape:\", feature.shape)\n",
        "  feature = feature.reshape(feature.shape[0], 1)\n",
        "  print(\"feature shape AFTER reshape:\", feature.shape)\n",
        "\n",
        "  print(\"x_in shape BEFORE one-hot-encoder:\", x_in.shape)\n",
        "\n",
        "  feature = onehot_encoder.fit_transform(feature)\n",
        "  print(f'feature shape={feature.shape}')\n",
        "  x_in = np.concatenate((x_in, feature), axis=1)\n",
        "  print(\"x_in shape AFTER one-hot-encoder: : \", x_in.shape)\n",
        "\n",
        "\n",
        "  y_in = data[y_column].values\n",
        "  selected_columns = ['timestamp_seconds', 'read_cache_miss', 'write_cache_miss', 'read_iops',\n",
        "                      'write_iops', 'read_throughput', 'write_throughput', 'read_iosz',\n",
        "                      'write_iosz', 'model_type'] #, 'datetime']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1aqd14xoFIU"
      },
      "source": [
        "# RUN this: utility function for plotting x vs y for a selected systemId  \n",
        "# x MUST be a list with a SINGLE string;  x=['cpu_utilization'];\n",
        "# y can be a list of any number of numerical features;\n",
        "def plot_multx_y(df, systemId, x, y, start_fraction, stop_fraction, linepattern, plot_1_column):\n",
        "  if len(x)>1:\n",
        "    raise ValueError(f'x-axis MUST be a list with a SINGLE string !')\n",
        "  df_temp = df[df['systemId']==systemId]\n",
        "  start = int(len(df_temp)*start_fraction)\n",
        "  stop = int(len(df_temp)*stop_fraction)\n",
        "  len_y = len(y)\n",
        "\n",
        "  if plot_1_column:\n",
        "    num_rows = len_y\n",
        "    num_cols = 1\n",
        "  else:\n",
        "    num_rows = math.ceil(math.sqrt(len_y))\n",
        "    num_cols = math.ceil(len_y/num_rows)\n",
        "\n",
        "  print(f'{len_y} figures, {num_rows} rows, {num_cols} columns')\n",
        "  y_index = 0\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      if y_index == (len_y):\n",
        "        break\n",
        "      plt.subplot(num_rows, num_cols, y_index+1)\n",
        "      plt.plot(df_temp[x[0]][start:stop], df_temp[y[y_index]][start:stop], linepattern)\n",
        "      plt.ylabel(f'{y[y_index]}')\n",
        "\n",
        "      plt.grid(True)\n",
        "      y_index = y_index + 1  \n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18.5, 3*num_rows)\n",
        "  fig.suptitle(f'systemId={systemId}, all the X-axes are from the column of {x[0]}')\n",
        "  plt.tight_layout() # 2nd last step in fig setting\n",
        "  fig.subplots_adjust(top=0.88) # last in fig setting\n",
        "  plt.show()\n",
        "  del df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQEmSQhlbYDE"
      },
      "source": [
        "# RUN this: plot the 'cpu_utilization' against each of the rest columns\n",
        "plot_1_column=False; x = ['cpu_utilization']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "#x = ['datetime']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "#x = ['read_iops']; y =['cpu_utilization']\n",
        "plot_multx_y(df, SYSTEM_ID_SELECTED, x ,y, 0.2, 0.3, '+', plot_1_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOz1Vvge_UjI"
      },
      "source": [
        "#x = ['cpu_utilization']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_1_column=True; x = ['datetime']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "#x = ['read_iops']; y =['cpu_utilization']\n",
        "plot_multx_y(df, SYSTEM_ID_SELECTED, x ,y, 0.2, 0.23, '+', plot_1_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJKivAI7y2Mm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyKrqN2PBzjT"
      },
      "source": [
        "#x = ['cpu_utilization']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_1_column=True; x = ['datetime']; y = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops', 'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "#x = ['read_iops']; y =['cpu_utilization']\n",
        "plot_multx_y(df, systemId_selected, x ,y, 0.2, 0.21, '-+', plot_1_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gja2Lth0Q_zO"
      },
      "source": [
        "def plot_all_timestamp_seconds(df_in, systemId, start_fraction, stop_fraction, linepattern ):\n",
        "  df = df_in\n",
        "  if (systemId[0] != 'all') & len(systemId)==1:\n",
        "    df = df_in[df_in['systemId']==systemId[0]]\n",
        "  start = int(len(df)*start_fraction)\n",
        "  stop = int(len(df)*stop_fraction)\n",
        "\n",
        "  print(f'len df={len(df)}')\n",
        "  fig, axs = plt.subplots(2)\n",
        "  fig.suptitle('timestamp_seconds')\n",
        "\n",
        "  axs[0].plot( df['timestamp_seconds'][start:stop], linepattern)\n",
        "  axs[0].set_title(f'systemId={systemId}:: series type')\n",
        "\n",
        "  axs[1].plot( np.array(df['timestamp_seconds'][start:stop]), linepattern)\n",
        "  axs[1].set_title(f'systemId={systemId}: array type')\n",
        "  fig.set_size_inches(12.5, 7.5)\n",
        "  del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0rNnGd9S3Cy"
      },
      "source": [
        "plot_all_timestamp_seconds(df, ['all'], 0, 1, '+')\n",
        "plot_all_timestamp_seconds(df, ['all'], 0, 0.1, '+')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4criErlDVgWW"
      },
      "source": [
        "plot_all_timestamp_seconds(df, ['sys1'], 0, 1, '+')\n",
        "plot_all_timestamp_seconds(df, ['sys1'], 0, 0.1, '+')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZU4c1oDa2e2"
      },
      "source": [
        "y = ['cpu_utilization']\n",
        "x = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "       'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_multx_y(df, systemId_selected, x ,y,'+', 0, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjyp35qibC1Z"
      },
      "source": [
        "SYSTEM_ID_SELECTED = 'sys2'\n",
        "y = ['datetime']\n",
        "x = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "       'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_multx_y(df, SYSTEM_ID_SELECTED, x ,y,'+', 0, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVh8vQeYp3Mx"
      },
      "source": [
        "def plot_diffby_datetime(df, systemId, x, periods, linepattern):\n",
        "  if type(periods) != int:\n",
        "    raise ValueError(f'periods {periods} must be a single integer!')\n",
        "\n",
        "  df_temp = df[df['systemId']==systemId]\n",
        "  t = df_temp['datetime']\n",
        "    \n",
        "  len_x = len(x)\n",
        "  num_rows = math.ceil(math.sqrt(len_x))\n",
        "  num_cols = math.ceil(len_x/num_rows)\n",
        "  print(f'{len_x} figures, {num_rows} rows, {num_cols} columns')\n",
        "\n",
        "  x_index = 0\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      x_array = df_temp[x[x_index]].diff(periods)\n",
        "      if x_index == (len_x):\n",
        "        break\n",
        "\n",
        "      plt.subplot(num_rows, num_cols, x_index+1)\n",
        "      plt.plot( t[periods:], x_array[periods:], linepattern)\n",
        "      plt.ylabel(f'{x[x_index]}')\n",
        "      plt.grid(True)\n",
        "      x_index = x_index + 1  \n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.suptitle(f'systemId={systemId}, time diff {periods}, x axis is df[datetime]')\n",
        "  plt.tight_layout()\n",
        "  fig.subplots_adjust(top=0.88)\n",
        "  fig.set_size_inches(12.5, 3*num_rows)\n",
        "  plt.show()\n",
        "  del df_temp\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju8rxEUXbNh3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mZhM-xNz1K3"
      },
      "source": [
        "def boxplot_diffby(df, systemId, x, periods):\n",
        "  if type(periods) != int:\n",
        "    raise ValueError(f'periods {periods} must be a single integer!')\n",
        "\n",
        "  df_temp = df[df['systemId']==systemId]\n",
        "    \n",
        "  len_x = len(x)\n",
        "  num_rows = math.ceil(math.sqrt(len_x))\n",
        "  num_cols = math.ceil(len_x/num_rows)\n",
        "  print(f'{len_x} figures, {num_rows} rows, {num_cols} columns')\n",
        "\n",
        "  x_index = 0\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      x_array = df_temp[x[x_index]].diff(periods)\n",
        "      if x_index == (len_x):\n",
        "        break\n",
        "\n",
        "      plt.subplot(num_rows, num_cols, x_index+1)\n",
        "      plt.boxplot( x_array[periods:])\n",
        "      plt.xlabel(f'{x[x_index]}')\n",
        "      plt.grid(True)\n",
        "      x_index = x_index + 1  \n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.suptitle(f'systemId={systemId}, time diff {periods}, x axis is df[datetime]')\n",
        "  plt.tight_layout()\n",
        "  fig.subplots_adjust(top=0.88)\n",
        "  fig.set_size_inches(12.5, 3*num_rows)\n",
        "  plt.show()\n",
        "  del df_temp\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSMEL6CBtHHK"
      },
      "source": [
        "periods = 1\n",
        "linepattern = '+'\n",
        "x = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "       'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_diffby_datetime(df, systemId_selected, x, periods, linepattern)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6PpUpgIzD5N"
      },
      "source": [
        "periods = 1\n",
        "linepattern = '+'\n",
        "x = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "       'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "plot_diffby_datetime(df, systemId_selected, x, periods, linepattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8aj7xE0SX4"
      },
      "source": [
        "periods = 1\n",
        "systemId = 'sys2'\n",
        "x = ['read_cache_miss', 'write_cache_miss', 'read_iops', 'write_iops',\n",
        "       'read_throughput', 'write_throughput', 'read_iosz','write_iosz', 'datetime']\n",
        "boxplot_diffby(df, systemId, x, periods)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhrFWxjvV3c"
      },
      "source": [
        "df.columns\n",
        "#plot_x_y(df, systemId, x, y, start_fraction, stop_fraction)\n",
        "plot_x_y(df, 'sys1', 'datetime','cpu_utilization',0.2, 0.3, '+')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZX4owfqYqhC"
      },
      "source": [
        "df.columns\n",
        "y = ['cpu_utilization']\n",
        "print(len(y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg-ETow7YnRf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3QZF7rl9B5W"
      },
      "source": [
        "plot_x_y(df, 'sys1', 'timestamp_seconds','cpu_utilization',)\n",
        "plot_all_timestamp_seconds(df)\n",
        "plot_sys1_timestamp_seconds(df)\n",
        "plot_part_sys1_timestamp_seconds(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVHCUaKdxDRw"
      },
      "source": [
        "plot_x_y(df, 'sys1', 'timestamp_seconds','cpu_utilization',)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HcP9kuU58A1"
      },
      "source": [
        "plot_all_timestamp_seconds(df)\n",
        "plot_sys1_timestamp_seconds(df)\n",
        "plot_part_sys1_timestamp_seconds(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC6r1OGBfdwW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkrTqqSxxH7T"
      },
      "source": [
        "plot_x_y(df, 'sys1', 'timestamp_seconds','cpu_utilization',)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wacBOaBOqdyw"
      },
      "source": [
        "plot_all_timestamp_seconds(df)\n",
        "plot_sys1_timestamp_seconds(df)\n",
        "plot_part_sys1_timestamp_seconds(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjH4osTLmG20"
      },
      "source": [
        "df['timestamp_seconds'].hist()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hR8smNm9bN"
      },
      "source": [
        "df['timestamp_seconds'].plot(kind='box')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ma4blmJfPSM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.values\n",
        "X_train, X_test = train_test_split(X, test_size=TEST_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke48eRpwff-n"
      },
      "source": [
        "print(f\"df.shape={df.shape}, type(X)={type(X)}, X.shape={X.shape}\") \n",
        "print(f\"X_train.shape={X_train.shape}, X_test.shape={X_test.shape}\")\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh-aVY29XAO0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SeGiqSHyz72"
      },
      "source": [
        "df.hist()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 8.5)\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OesKKX99zmFy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a57elgsnyjK-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF5qqPmeErjG"
      },
      "source": [
        "## Q2. Group on systemId and one week's duration and then calculate following custom metrics\n",
        "- std/median on columns read_iops, read_cache_miss\n",
        "- rolling mean on columns write_throughput and write_iosz\n",
        "- exponential moving average on column write_cache_miss and write_iops\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbo5DppFI8Z5"
      },
      "source": [
        "features = [['read_iops', 'read_cache_miss'],\n",
        "            ['write_throughput', 'write_iosz'],\n",
        "            ['write_cache_miss', 'write_iops']]\n",
        "\n",
        "for k in range(len(features)):\n",
        "  print(features[k])\n",
        "  for x in features[k]:\n",
        "    print(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGTrcA4qzwpl"
      },
      "source": [
        "dftemp = df[['systemId', 'read_iops', 'read_cache_miss']]\n",
        "df_grouped = dftemp.groupby('systemId')\n",
        "\n",
        "ct = 0\n",
        "for group_name, df_group in df_grouped:\n",
        "  ct = ct + 1\n",
        "  if ct>2: \n",
        "    break\n",
        "  \n",
        "  df_group = df_group.sort_index()\n",
        "\n",
        "  print(f'\\n\\n ****** {group_name} , shape={df_group.shape}****') \n",
        "  print(df_group.head())\n",
        "\n",
        "  stat = df_group.resample('W', origin='start').sum()\n",
        "  print(f'\\n ****** {group_name} sum, shape={stat.shape}****') \n",
        "  print(stat)\n",
        "\n",
        "  stat = df_group.resample('W', origin='start').median()\n",
        "  print(f'\\n ****** {group_name} median, shape={stat.shape}****') \n",
        "  print(stat)\n",
        "    \n",
        "  stat = df_group.resample('W', origin='start').std()\n",
        "  print(f'\\n ****** {group_name} std, shape={stat.shape}****') \n",
        "  print(stat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X95XEn3P-NBO"
      },
      "source": [
        "# normalization\n",
        "# defiine columns_to_scale\n",
        "df_plot = df.copy()\n",
        "\n",
        "columns_to_scale = list(df_plot.columns)\n",
        "columns_to_scale.remove('systemId')\n",
        "columns_to_scale.remove('model_type')\n",
        "print(columns_to_scale)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeCApQCy_FfT"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "autoscaler = StandardScaler()\n",
        "df_plot[columns_to_scale] = autoscaler.fit_transform(df_plot[columns_to_scale])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHkU25Ue_rzP"
      },
      "source": [
        "df_plot.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1dscO5lqEYv"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# add labelencoder to systemId and model_type\n",
        "label_encoder1 = LabelEncoder()\n",
        "df_plot['systemId'] = label_encoder1.fit_transform(df_plot['systemId'])\n",
        "label_encoder2 = LabelEncoder()\n",
        "df_plot['model_type'] = label_encoder2.fit_transform(df_plot['model_type'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbdtFZOv21OA"
      },
      "source": [
        "df_plot.head()\n",
        "columns_to_scale = df_plot.columns\n",
        "print(columns_to_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5g-ThshpIg"
      },
      "source": [
        "plot_features = df_plot[columns_to_scale]\n",
        "plot_features.index = df_plot['timestamp_seconds']\n",
        "_ = plot_features.plot(subplots=True)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_9uStkFBSk4"
      },
      "source": [
        "samples = int(24*60/5)\n",
        "plot_features = df_plot[columns_to_scale][:samples]\n",
        "plot_features.index = df_plot['timestamp_seconds'][:samples]\n",
        "_ = plot_features.plot(subplots=True)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_mF9RDClDYa"
      },
      "source": [
        "# sample period is 5 min\n",
        "sample_period = 5\n",
        "plot_len = int(24*60/5)\n",
        "plot_features = df[columns_to_scale][:plot_len]\n",
        "plot_features.index = df_temp_sysId['timestamp_seconds'][:plot_len]\n",
        "_ = plot_features.plot(subplots=True)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz4m1j8LrneQ"
      },
      "source": [
        "\n",
        "boxplot = df_temp_sysId.boxplot(column=columns_to_scale)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-oR6Synoq9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQm1OUQ6wDkt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLLwCg1lo2qO"
      },
      "source": [
        "sample_period = 5\n",
        "plot_len = int(2*24*60/5) # plot 2 day\n",
        "\n",
        "plt.plot(np.array(df_temp_sysId['Day sin'])[:plot_len], '+')\n",
        "plt.plot(np.array(df_temp_sysId['Day cos'])[:plot_len], '+')\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SlxA04JpkXD"
      },
      "source": [
        "plt.plot(np.array(df_temp_sysId['Year sin'])[:plot_len], '+')\n",
        "plt.plot(np.array(df_temp_sysId['Year cos'])[:plot_len], '+')\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of Year signal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmM33BT-oV9B"
      },
      "source": [
        "df_temp_sysId.describe().T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V74KW2qUp1Bm"
      },
      "source": [
        "# fft plot TODO: for time ordered and single systemId \n",
        "import tensorflow as tf\n",
        "fft = tf.signal.rfft(df_temp_sysId['cpu_utilization'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df_temp_sysId['cpu_utilization'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "#plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBkUWwHglsuq"
      },
      "source": [
        "cols_std =  ['read_iops', 'read_cache_miss']\n",
        "cols_rolling_mean = ['write_throughput', 'write_iosz']\n",
        "cols_exp_mvavg = ['write_cache_miss', 'write_iops']\n",
        "\n",
        "group_by_systemId = df_temp.groupby(\"systemId\") #, axis=\"columns\"\n",
        "group = group_by_systemId.get_group('sys1')\n",
        "group = group[['timestamp_seconds', 'write_throughput', 'write_iosz']]\n",
        "\n",
        "print(f'len ={len(group)}')\n",
        "group.head(8)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v2tIIpH30oO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpwL0lf1304n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMvlqIcDwVoC"
      },
      "source": [
        "group = group.sort_values(by='timestamp_seconds')\n",
        "group.head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRDklfCQwcGf"
      },
      "source": [
        "tmp = group.rolling(2).mean()\n",
        "tmp.head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tkAAvJ2wKDP"
      },
      "source": [
        "group['rmean_write_throughput'] = tmp['write_throughput']\n",
        "group['rmean_write_iosz'] = tmp['write_iosz']\n",
        "group.head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVK4DMG6E5DQ"
      },
      "source": [
        "\n",
        "if 0:\n",
        "  summary = []\n",
        "  for name, group in group_by_systemId:\n",
        "    summary.append(\n",
        "      {\n",
        "        name : \n",
        "          {\n",
        "            'length': len(group),\n",
        "            'min': group['read_iops'].min(),\n",
        "            'max': group['read_iops'].max(),\n",
        "            'mean': group['read_iops'].mean(),\n",
        "            'std': group['read_iops'].std(),\n",
        "            'median': group['read_iops'].median()\n",
        "          }\n",
        "      }\n",
        "    )\n",
        "  if 0:\n",
        "    print(f'name={name}, len = {len(group)}\\n')\n",
        "    print('systemId uniques=', np.unique(group['systemId']))\n",
        "    #print(f'group={group.head(2)}\\n')\n",
        "    print(f'summary={summary}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpcmd8lhQwDh"
      },
      "source": [
        "## Q3. Generate a random distribution of samples from data such that each day should contain 12 continous samples and start of the sample should be random with that day"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyzNxQmp3OkJ"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBnxojpJ3j8R"
      },
      "source": [
        "# note timestamp_seconds is converted to sin cos of day hour so not used here\n",
        "df_X = df[['systemId', 'model_type']].copy()\n",
        "\n",
        "print(f'df_X: {df_X.columns}')\n",
        "print(f'df: {df.columns}')\n",
        "\n",
        "print(f'y: {df_Y}')\n",
        "print(df['cpu_utilization'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyMd1Yi66lAc"
      },
      "source": [
        "# one-hot-encoder of systemId and model_type\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X = df_X.values\n",
        "X = X.astype(str)\n",
        "\n",
        "print(f'X={X[:3, :]}')\n",
        "print(f'Y={Y[:3]}')\n",
        "print(f'X shape={X.shape}')\n",
        "print(f'Y shape={Y.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsThehZX7zeB"
      },
      "source": [
        "# encode string input values as integers\n",
        "encoded_x = None\n",
        "for i in range(0, X.shape[1]):\n",
        "\tlabel_encoder = LabelEncoder()\n",
        "\tfeature = label_encoder.fit_transform(X[:,i])\n",
        "\tfeature = feature.reshape(X.shape[0], 1)\n",
        "\tonehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "\tfeature = onehot_encoder.fit_transform(feature)\n",
        "\tprint(f'i={i}, shape={feature.shape}')\n",
        "\tif encoded_x is None:\n",
        "\t\tencoded_x = feature\n",
        "\telse:\n",
        "\t\tencoded_x = np.concatenate((encoded_x, feature), axis=1)\n",
        "  \n",
        "print(\"X shape: : \", encoded_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qOasz4I9HQ7"
      },
      "source": [
        "df_X = df.copy()\n",
        "features_added_X = ['timestamp_seconds', 'cpu_utilization', 'systemId', 'model_type']\n",
        "for i in features_added_X:\n",
        "  del df_X[i]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSBTdVSU_Wj4"
      },
      "source": [
        "print(df_X.columns)\n",
        "print(df_X.shape)\n",
        "print(encoded_x.shape)\n",
        "df_X.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGQ2QDUA-UQC"
      },
      "source": [
        "# Now encoded_x  contains the (27 for systemId) + (3 for model) = 30 categorical columns \n",
        "# Here, concatenate X's non-categorical 12 columns df_X with encoded_x to get a total of 42 columns\n",
        "X = np.concatenate((encoded_x, df_X.values), axis=1)\n",
        "print(\"X shape: : \", X.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEpxO2G7EBmY"
      },
      "source": [
        "Y = df['cpu_utilization'].values\n",
        "print(\"Y shape: : \", Y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kX575JMFcdg"
      },
      "source": [
        "## Q4. Fit a linear regression to this data with y as \"cpu_utilization\" column. Comment on the fit of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "rIB0EOqZYNOT",
        "outputId": "e2c62251-0ee4-4a71-96d6-d935dc246cea"
      },
      "source": [
        "# Use LinearRegression for regression, DecisionTreeRegressor for feature selection\n",
        "# explore the number of selected features for RFE\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "n_features_to_select = [2, len(x_cols)]\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset(X, Y):\n",
        "\tX, y = X, Y\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(n_features_to_select[0], n_features_to_select[1]):\n",
        "\t\t#rfe = RFE(estimator=LinearRegression(), n_features_to_select=i)\n",
        "\t\trfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=i)\n",
        "\t\tmodel = LinearRegression()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = KFold(n_splits=10, shuffle=False, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset(X, Y)\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()\n",
        "pyplot.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">2 -0.237 (0.025)\n",
            ">3 -0.096 (0.021)\n",
            ">4 -0.082 (0.018)\n",
            ">5 -0.065 (0.009)\n",
            ">6 -0.061 (0.008)\n",
            ">7 -0.061 (0.008)\n",
            ">8 -0.061 (0.008)\n",
            ">9 -0.061 (0.008)\n",
            ">10 -0.060 (0.008)\n",
            ">11 -0.059 (0.008)\n",
            ">12 -0.058 (0.009)\n",
            ">13 -0.058 (0.008)\n",
            ">14 -0.058 (0.008)\n",
            ">15 -0.058 (0.008)\n",
            ">16 -0.058 (0.008)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "1eL3dMJyUnxm",
        "outputId": "326856ef-5b14-4f25-9d5b-8291b9892f66"
      },
      "source": [
        "# Use LinearRegression for regression, LinearRegression for feature selection\n",
        "# DecisionTreeRegressor for feature selection ??? TODO\n",
        "# explore the number of selected features for RFE\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "n_features_to_select = [2, len(x_cols)]\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset(X, Y):\n",
        "\tX, y = X, Y\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(n_features_to_select[0], n_features_to_select[1]):\n",
        "\t\t#rfe = RFE(estimator=LinearRegression(), n_features_to_select=i)\n",
        "\t\trfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=i)\n",
        "\t\tmodel = LinearRegression()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = KFold(n_splits=10, shuffle=False, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset(X, Y)\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()\n",
        "pyplot.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">2 -0.228 (0.032)\n",
            ">3 -0.142 (0.027)\n",
            ">4 -0.069 (0.008)\n",
            ">5 -0.065 (0.010)\n",
            ">6 -0.063 (0.009)\n",
            ">7 -0.058 (0.008)\n",
            ">8 -0.058 (0.008)\n",
            ">9 -0.058 (0.009)\n",
            ">10 -0.058 (0.009)\n",
            ">11 -0.058 (0.008)\n",
            ">12 -0.058 (0.008)\n",
            ">13 -0.058 (0.008)\n",
            ">14 -0.058 (0.008)\n",
            ">15 -0.058 (0.008)\n",
            ">16 -0.058 (0.008)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYdElEQVR4nO3df5BdZ13H8fcnv1poabvbhDRtwEQpGJPBSJdaa6jSpNAiQyoiyiAmmk7F0YoileIiTQczUyxanPzhTkwooTYRCG1ScQxNk6BkRupsYpKmRkmQKin5sW0WWkkbLtmvf9yz6d3Nvbt77zk3u/c+n9fMmT0/nvu9T052z+ee55x7ryICMzNL16Tx7oCZmY0vB4GZWeIcBGZmiXMQmJklzkFgZpa4KePdgUZMnz495syZM97dMDNrKbt37342ImYMX9+SQTBnzhx6e3vHuxtmZi1F0v9UW++hITOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEt+YYya2+Sqq6fqN+dUau/kL/PrbYvrDXlOiOQ1Clpm6RD2c+OGu2WZW0OSVpWsf5rkv5L0t5senWe/lh7iIizU+VyXpJqTs3obxF9brV90ay6I9VuVt2U9kXeoaG7gO0RcTWwPVseQlIncDfws8C1wN3DAuP9EbEwm07k7I9ZTc08YLeaZu2LVgzFVt4XRdXNGwRLgfXZ/Hrg1ipt3g5si4iTEdEPbANuzvm8ZmZWkLxBMDMijmbzx4CZVdpcBXynYvlItm7QA9mw0J9phHMbSbdL6pXU29fXl7PbllczT3vN7Pwa9WKxpMeBK6ps6q5ciIiQVO+5yfsj4hlJrwK+DHwA+Hy1hhGxBlgD0NXVld65/ARTeRoqKcnhFbN2MWoQRMSSWtskHZc0KyKOSpoFVBvjfwb4xYrl2cDXstrPZD9fkLSB8jWEqkFg7a2zs5P+/v6q24afZXR0dHDy5Mnz0S2zJOQdGnoUGLwLaBmwpUqbrwJvk9SRXSR+G/BVSVMkTQeQNBV4J3AgZ39smFYZwunv7x9y0WukqVZgVNPZ2Vnz3z58XWdnZ119rla7Wt16azerz94Xza9bq3a1ukX0uYi6AGP+46s2AZdTvlvoEPA40Jmt7wLWVrT7beBwNv1Wtu4iYDewH3gK+Gtg8lie95prrgmrX/m/e2LWrVbjxA9OxLJ/WhZ9p/oafr5m1a3Wvlbdemt7X4zc1vui8bpAb1Q5puY6I4iI5yJicURcHRFLIuJktr43Im6raPfZiHhdNj2QrftBRFwTEW+MiPkR8aGIOJOnP9Z8zXpVEndfAisvHTL1rHsze4710rO2a8j6uPuSXP+Gnv097Dm+h559PbnqDO9zrf5OpD63et1m1k65rqIFL/J1dXWFv6qyfkVc1K2nRp62faf6uOXhWzh95jQXTL6Arb+ylemvmF53XVZeOmSxb/Ikbpl9JacnTeKCgQG2Hvku088MVLT//tjqDuvHSP2dMH1u4r6orD1q3YnQ5xbfF43WlbQ7IrrOWe8gmBhqjdk38v8z0oXXauq5+Hq+guCT3/gkjxx6hNJAiamTpvLuq9/Nx6/7+ISpO7z9SHUnSp+9L5pfd3j7Zu2LRuvWCgJ/6NwEUTleV7nciHouvEadF1+H6zvVx/Kty3n2xWcbrlGt5pbDWygNlAAoDZTYfHhz7udotbqt2Gfvi9as6yCwXJox/tmzv4eBGHqaOxADuZ+j1eo2s3ar1W1mbdf1p48mo+9UH3f+y518+hc+PWTsul5nL5BSHqfcMvtKYtIkNh/cyAe3/eWQccpGL5DuO7Hv7KudQaWBEntP7G24361Yt5m1W61uM2u7rq8RjKt6xvLrehPVsAthAJ+8vIMvvepi3vvC//Hx56o85xgvWJ2vseCJ3nai9GMitJ0o/ZgIbSdKP+q9RuAzgnE0OJY/FrUuJldte8/z59yBs+XhW4gzp9ncMZ0P3tZ77h0tK8dc/uWaVcYpP/jTH2z4jGOs/8aOjqqfdn7e6za7ttn54msECagcU5yo47W1LmRX21bPx0s0q26t2rXW11u72vsyqk2NhGIz6rZin70vXuYgmGCKvgunGXcYSGL9Y+urjlN+7rHP5foDMofi+ehzu+yLIuqCh4YmnMq7cCrH2+s1OGQx6wOz6Lihg0lTX878F196kTf+zhs5+mD5E8TrOWAP/vKNNCTSitedzFLmM4IJZPDVexC5XrVXvjK4/j3XDwkBgElTJ3H9e65v+NXD8Oeo9irFzFqHzwjGUeWtmAA9l3cwcPHFMEkMlF6iZ23X2Tt8Gr0Vc9O7Np2dr/fuBzNLg4NgHFXe3TN4Z0/pzGkASpM05A6fRu7sMTMbCw8NTRDNfEemmdlIHATjbPAOm9HuwvEdONYKKm9hrLbcjNrNqpu39vnYF0XV9dDQOKo1Xn/OWP4nzlOHzHJq5jWoZtVutbrNqO0gsAln+CubweW8v/y16uat3ay6I9WeqPvCWpODwCacVnuF1kqv/Jpd11qTg6DN+ZWfmY3GQdDmfLA3s9H4riEzs8Q5CMzMEucgMDNLnIPAGrZx40YWLFjA5MmTWbBgARs3bhzvLplZAxwECWjGAXvjxo10d3ezevVqXnrpJVavXk13d7fDwKwVjfRxwhN1uuaaa6LdAFWnvDZs2BBz586NHTt2xA9/+MPYsWNHzJ07NzZs2JCr7vz582PHjh1D1u3YsSPmz5+fq66ZNQ/QG1WOqf7y+ja3YMECVq9ezVvf+taz63bu3Mkdd9zBgQMHGq47efJkXnrpJaZOnXp2XalU4sILL+TMmTO5+mxmzVHry+s9NNTmDh48yKJFi4asW7RoEQcPHsxVd968eezatWvIul27djFv3rxcdc3s/HMQtLlmHbC7u7tZsWIFO3fupFQqsXPnTlasWEF3d3euumZ2/vmdxW1u8IC9bt06Fi1axK5du1ixYgWrVq3KVfd973sfAHfccQcHDx5k3rx5rFq16ux6M2sdvkaQgI0bN7Jq1aqzB+zu7m4fsM0SVOsagYPAzCwRvlhsZmZVOQjMzBLnIDAzS1yuIJDUKWmbpEPZz6rfsC5pq6TvSfrKsPVzJT0h6bCkL0ialqc/ZmZWv7xnBHcB2yPiamB7tlzNfcAHqqz/FHB/RLwO6AdW5OyPmZnVKW8QLAXWZ/PrgVurNYqI7cALletU/s7EG4FNoz3ezMyaJ28QzIyIo9n8MWBmHY+9HPheRPwoWz4CXJWzP2ZmVqdR31ks6XHgiiqbhnyWQESEpKa9KUHS7cDtAK997Wub9TRmZskZNQgiYkmtbZKOS5oVEUclzQJO1PHczwGXSZqSnRXMBp4ZoR9rgDVQfkNZHc9jZmYjyDs09CiwLJtfBmwZ6wOzz8beCbynkcebmVkx8gbBvcBNkg4BS7JlJHVJWjvYSNLXgS8BiyUdkfT2bNNHgQ9LOkz5msG6nP0xM7M65fr00Yh4DlhcZX0vcFvF8ltqPP6/gWvz9OF8K9/sdK5W/MwmMzPwx1DXbfCAL8kHfzNrC/6ICTOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOgjHo7OxE0pAJOGedJDo7O8e5t2Zm9fGnj45Bf3//mD9ptNbHVJuZTVQ+IzAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ6CBvSd6mP51uU8++Kz490VM7PcHAQN6Nnfw57je+jZ1zPeXTEzy81BUKe+U31sObyFINh8eLPPCsys5TkI6tSzv4eBGABgIAZ8VmBmLc9BUIfBs4HSQAmA0kDJZwVm1vIcBHWoPBsY5LMCM2t1/vL6MYi7L4GVl7LvyisoXTBtyLbSQIm9+x+Erfe93NbMrIXkCgJJncAXgDnA08B7I6K/SrutwHXAroh4Z8X6zwG/AHw/W7U8Ivbm6VMz6J7niQg2jaWtRKxsdo/MzIqTd2joLmB7RFwNbM+Wq7kP+ECNbXdGxMJsmnAhYGbW7vIGwVJgfTa/Hri1WqOI2A68kPO5zMysCfIGwcyIOJrNHwNmNlBjlaT9ku6XdEGtRpJul9Qrqbevr6+hzpqZ2blGDQJJj0s6UGVaWtkuIgKIOp//Y8BPAm8GOoGP1moYEWsioisiumbMmFHn05iZWS2jXiyOiCW1tkk6LmlWRByVNAs4Uc+TV5xNnJb0APCReh5vZmb55R0aehRYls0vA7bU8+AsPJAkytcXDuTsj5mZ1SlvENwL3CTpELAkW0ZSl6S1g40kfR34ErBY0hFJb882PSTpSeBJYDrw5zn7Y2Zmdcr1PoKIeA5YXGV9L3BbxfJbajz+xjzPfz6VT1pG19HR0eSemJkVy+8sHoPydfChJFVdb2bWavxZQ2ZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpa4tvw+gpG+RMbfIWBmNlRbBkHlwd5fIGNmNjIPDZmZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuFxBIKlT0jZJh7KfHVXaLJT0r5KekrRf0q9VbJsr6QlJhyV9QdK0PP0xM7P65T0juAvYHhFXA9uz5eFOAb8ZEfOBm4HPSLos2/Yp4P6IeB3QD6zI2R8zM6tT3iBYCqzP5tcDtw5vEBHfjIhD2fx3gRPADEkCbgQ2jfT4iUYS5a6/PD+4bGbWivIGwcyIOJrNHwNmjtRY0rXANOBbwOXA9yLiR9nmI8BVIzz2dkm9knr7+vpydrtxEVF1MjNrVVNGayDpceCKKpu6KxciIiTVPCJKmgU8CCyLiIF6X0VHxBpgDUBXV5ePvGZmBRk1CCJiSa1tko5LmhURR7MD/Yka7S4B/hHojohvZKufAy6TNCU7K5gNPFP3vyDT2dlJf39/rX6es66jo4OTJ082+nRmZm0j79DQo8CybH4ZsGV4g+xOoEeAz0fE4PUAojyeshN4z0iPH6v+/v6awzbVplqhYWaWmrxBcC9wk6RDwJJsGUldktZmbd4L3AAsl7Q3mxZm2z4KfFjSYcrXDNbl7I+ZmdVJrXihs6urK3p7e4esk1TXRdt625uZtTpJuyOia/h6v7PYzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLXFsHQd+pPpZvXc6zLz473l0xM5uw2joIevb3sOf4Hnr29Yx3V8zMJqy2DYK+U31sObyFINh8eLPPCszMamjbIOjZ38NADAAwEAM+KzAzq6Etg2DwbKA0UAKgNFDyWYGZWQ1tGQSVZwODfFZgZlbdlPHuQFHi7ktg5aUA7LvyCkoXTBuyvTRQYu/+B2HrfS+3NzOz9gkC3fM8EQHAprG0l4iVTe2SmVlLaMuhITMzGzsHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSUuVxBI6pS0TdKh7GdHlTYLJf2rpKck7Zf0axXbPifp25L2ZtPCPP0xM7P65T0juAvYHhFXA9uz5eFOAb8ZEfOBm4HPSLqsYvudEbEwm/bm7I+ZmdUpbxAsBdZn8+uBW4c3iIhvRsShbP67wAlgRs7nNTOzguQNgpkRcTSbPwbMHKmxpGuBacC3KlavyoaM7pd0wQiPvV1Sr6Tevr6+nN02M7NBowaBpMclHagyLa1sF+VvhYkR6swCHgR+K+Ls90h+DPhJ4M1AJ/DRWo+PiDUR0RURXTNm+ITCzKwoo35DWUQsqbVN0nFJsyLiaHagP1Gj3SXAPwLdEfGNitqDZxOnJT0AfKSu3puZWW55h4YeBZZl88uALcMbSJoGPAJ8PiI2Dds2K/spytcXDuTsj5mZ1SlvENwL3CTpELAkW0ZSl6S1WZv3AjcAy6vcJvqQpCeBJ4HpwJ/n7I+ZmdVJg1/43kq6urqit7d3yDpJ1PNvqbe9mVmrk7Q7IrqGr/c7i83MEjfqxeJWUr7UMDYdHee8CdrMLEltEwS1hnk8BGRmNjIPDZmZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuLa5fbTS8PcTVC77VlIzs6HaMgh8sDczGzsPDZmZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolrye8sltQH/M8Ym08Hnm1CN5pVt5m1W61uM2u3Wt1m1m61us2s3e51fywiZgxf2ZJBUA9JvdW+rHmi1m1m7Var28zarVa3mbVbrW4za6da10NDZmaJcxCYmSUuhSBY02J1m1m71eo2s3ar1W1m7Var28zaSdZt+2sEZmY2shTOCMzMbAQOAjOzxLVtEEh6jaSdkv5D0lOSPlRQ3Qsl/ZukfVnde4qoW1F/sqR/l/SVgus+LelJSXsl9RZY9zJJmyT9p6SDkn6ugJpvyPo5OD0v6Q8L6u8fZf9vByRtlHRhEXWz2h/K6j6Vp7+SPivphKQDFes6JW2TdCj72VFg7V/N+jwgqaFbEWvUvS/7vdgv6RFJlxVU95NZzb2SHpN0ZVF9rtj2x5JC0vSC+rxS0jMVv9PvKKq/ku7I9vNTkv6i3rpA+du82nECZgFvyuZfBXwT+KkC6gq4OJufCjwBXFdgvz8MbAC+UvD+eBqY3oT9vB64LZufBlxWcP3JwDHKb4TJW+sq4NvAK7LlLwLLC+rnAuAA8ErK3/z3OPC6BmvdALwJOFCx7i+Au7L5u4BPFVh7HvAG4GtAV4F13wZMyeY/1Uifa9S9pGL+D4CeovqcrX8N8FXKb1qt+2+mRp9XAh/J+TtWre5bs9+1C7LlVzdSu23PCCLiaETsyeZfAA5SPhDkrRsR8X/Z4tRsKuSKu6TZwC8Ba4uo12ySLqX8y7kOICJ+GBHfK/hpFgPfioixvpN8NFOAV0iaQvmg/d2C6s4DnoiIUxHxI+CfgXc3Uigi/gU4OWz1UsqhS/bz1qJqR8TBiPivRuqNUvexbF8AfAOYXVDd5ysWL6LBv78a+xngfuBPmlA3lxp1fxe4NyJOZ21ONFK7bYOgkqQ5wM9QfvVeRL3JkvYCJ4BtEVFIXeAzlH8BBwqqVymAxyTtlnR7QTXnAn3AA9lw1lpJFxVUe9CvAxuLKBQRzwCfBv4XOAp8PyIeK6I25bOBt0i6XNIrgXdQfmVZlJkRcTSbPwbMLLD2+fDbwD8VVUzSKknfAd4PfKLAukuBZyJiX1E1K/x+NqT12UaH9qp4PeXfuyck/bOkNzdSpO2DQNLFwJeBPxz2SqJhEXEmIhZSfoVzraQFeWtKeidwIiJ25+5gdYsi4k3ALcDvSbqhgJpTKJ+q/k1E/AzwA8rDFoWQNA14F/Clgup1UH5lPRe4ErhI0m8UUTsiDlIe/ngM2ArsBc4UUbvKcwUFnYWeD5K6gR8BDxVVMyK6I+I1Wc3fL6JmFuB/SoHBUuFvgJ8AFlJ+EfKXBdWdAnQC1wF3Al+UpHqLtHUQSJpKOQQeioiHi66fDYPsBG4uoNzPA++S9DTw98CNkv6ugLrA2VfDg6eOjwDXFlD2CHCk4oxoE+VgKMotwJ6IOF5QvSXAtyOiLyJKwMPA9QXVJiLWRcQ1EXED0E/5ulRRjkuaBZD9bGgI4HyTtBx4J/D+LMCK9hDwKwXV+gnKLxL2ZX+Hs4E9kq7IWzgijmcvIAeAv6WYvz8o/w0+nA1Z/xvl0YS6L3C3bRBkqbgOOBgRf1Vg3RmDdz9IegVwE/CfeetGxMciYnZEzKE8HLIjIgp5tSrpIkmvGpynfBHvnDsl6hURx4DvSHpDtmox8B9561Z4HwUNC2X+F7hO0iuz34/FlK8dFULSq7Ofr6V8fWBDUbWBR4Fl2fwyYEuBtZtC0s2UhzrfFRGnCqx7dcXiUgr4+wOIiCcj4tURMSf7OzxC+YaTY3lrD4Z45pcp4O8vs5nyBWMkvZ7yDRv1f8ppnqvYE3kCFlE+fd5P+TR9L/COAuq+Efj3rO4B4BNN6PsvUuBdQ8CPA/uy6Smgu8DaC4HebH9sBjoKqnsR8BxwacH79h7KB44DwINkd1sUVPvrlINwH7A4R52NlIcPSpQPRiuAy4HtwCHKd4l0Flj7l7P508Bx4KsF1T0MfKfi76/uu3tq1P1y9v+3H/gH4Kqi9sWw7U/T2F1D1fr8IPBk1udHgVkF1Z0G/F22P/YANzayL/wRE2ZmiWvboSEzMxsbB4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmift/eLli7HwigSgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCQb4VZIVVFd",
        "outputId": "be67bed8-09ef-4a5b-ff25-d3f71b617673"
      },
      "source": [
        "import sklearn.metrics as skmetrics\n",
        "sorted(skmetrics.SCORERS.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_brier_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_gamma_deviance',\n",
              " 'neg_mean_poisson_deviance',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'neg_root_mean_squared_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'roc_auc_ovo',\n",
              " 'roc_auc_ovo_weighted',\n",
              " 'roc_auc_ovr',\n",
              " 'roc_auc_ovr_weighted',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zREitEanNuH"
      },
      "source": [
        "## Q5. Create a column where cpu_utilization < 20 is 0 and cpu_utilization >= 20 as 1. Using this newly created column build a logistic regression. Commment on the evaluation of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twy9oe8xnNRM"
      },
      "source": [
        "print(X.shape, Y.shape)\n",
        "print(data_cols, '\\n', x_cols)\n",
        "print(type(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG8Kz56q2VPx"
      },
      "source": [
        "target_threshold = target_transformer.transform([[20]])\n",
        "target_threshold = target_threshold[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bjufSXFnND8"
      },
      "source": [
        "f = lambda x: x>target_threshold\n",
        "Y_cat = f(Y)*1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd5FUhHC2JCb"
      },
      "source": [
        "_=plt.hist(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Bd9EmonM2_"
      },
      "source": [
        "_= plt.hist(Y_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hBbzJ8G3Tht"
      },
      "source": [
        "# Get orignal target w/o transformation from df\n",
        "def get_target(df, systemId_selected, numerical_transform_cols):\n",
        "  if systemId_selected[0] == 'All':\n",
        "    df_tmp = df[numerical_transform_cols]\n",
        "  else:  \n",
        "    df_tmp = df[df['systemId']==systemId_selected[0]][numerical_transform_cols]\n",
        "  return df_tmp.values\n",
        "\n",
        "y_real = get_target(df, SYSTEM_ID_SELECTED, 'cpu_utilization' )\n",
        "#_= plt.hist(y_real)\n",
        "\n",
        "f1 = lambda x: x>20\n",
        "y_real_cat = f1(y_real)*1\n",
        "_= plt.hist(y_real_cat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "1f4_54yf88xW",
        "outputId": "0e7651bb-51f6-41e3-f856-23b85b214287"
      },
      "source": [
        "# Use LogisticRegression for classification, DecisionTreeClassifier for feature selection\n",
        "\n",
        "# explore the number of selected features for RFE\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "n_features_to_select = [2, len(x_cols)]\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset(X, Y):\n",
        "\tX, y = X, Y\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(n_features_to_select[0], n_features_to_select[1]):\n",
        "\t\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
        "\t\tmodel = LogisticRegression()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset(X, Y_cat)\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">2 0.873 (0.011)\n",
            ">3 0.917 (0.010)\n",
            ">4 0.927 (0.010)\n",
            ">5 0.931 (0.011)\n",
            ">6 0.933 (0.011)\n",
            ">7 0.934 (0.010)\n",
            ">8 0.934 (0.009)\n",
            ">9 0.934 (0.009)\n",
            ">10 0.934 (0.009)\n",
            ">11 0.935 (0.010)\n",
            ">12 0.936 (0.010)\n",
            ">13 0.936 (0.010)\n",
            ">14 0.935 (0.010)\n",
            ">15 0.936 (0.009)\n",
            ">16 0.936 (0.009)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWPq13WoFkwb"
      },
      "source": [
        "## Q6. Fit a simple decision tree regressor to this data. Comment about the fit of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm-XHcuoFzD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "e0fb9340-cce6-4e3d-baec-9b1ee4c4c29c"
      },
      "source": [
        "# explore the number of selected features for RFE\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "n_features_to_select = [2, len(x_cols)]\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset(X, Y):\n",
        "\tX, y = X, Y\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(n_features_to_select[0], n_features_to_select[1]):\n",
        "\t\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
        "\t\tmodel = DecisionTreeClassifier()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset(X, Y_cat)\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">2 0.818 (0.013)\n",
            ">3 0.888 (0.012)\n",
            ">4 0.902 (0.012)\n",
            ">5 0.905 (0.011)\n",
            ">6 0.910 (0.009)\n",
            ">7 0.911 (0.012)\n",
            ">8 0.911 (0.012)\n",
            ">9 0.907 (0.011)\n",
            ">10 0.906 (0.012)\n",
            ">11 0.908 (0.011)\n",
            ">12 0.907 (0.010)\n",
            ">13 0.908 (0.009)\n",
            ">14 0.906 (0.009)\n",
            ">15 0.905 (0.010)\n",
            ">16 0.906 (0.010)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISHSD3FTQV2H"
      },
      "source": [
        "## Q7. Fit a Random forest regressor. Compare this with simple dicision tree. If Random forest is better then why"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq5mWNf3QkUD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "27fb9b5c-d7f5-4f84-e02b-727cc4abb566"
      },
      "source": [
        "# Use RandomForestClassifier for classification, DecisionTreeClassifier for feature selection\n",
        "# TODO: add f1-score for biased classification\n",
        "# explore the number of selected features for RFE\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "n_features_to_select = [2, len(x_cols)]\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset(X, Y):\n",
        "\tX, y = X, Y\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(n_features_to_select[0], n_features_to_select[1]):\n",
        "\t\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
        "\t\tmodel = RandomForestClassifier()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset(X, Y_cat)\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">2 0.853 (0.011)\n",
            ">3 0.917 (0.010)\n",
            ">4 0.929 (0.009)\n",
            ">5 0.932 (0.009)\n",
            ">6 0.936 (0.009)\n",
            ">7 0.939 (0.008)\n",
            ">8 0.940 (0.007)\n",
            ">9 0.940 (0.007)\n",
            ">10 0.940 (0.008)\n",
            ">11 0.940 (0.008)\n",
            ">12 0.941 (0.008)\n",
            ">13 0.940 (0.008)\n",
            ">14 0.940 (0.008)\n",
            ">15 0.941 (0.009)\n",
            ">16 0.940 (0.008)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_oc59AaQl_2"
      },
      "source": [
        "## Q8. How do improve the accuracy of Random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPz1m2MCQs5C"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el_i1OMb9Gmh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1BGrdNA8gSE"
      },
      "source": [
        "## Q9. Cluster the input variables using KMeans and GMM.\n",
        "       \n",
        "1.   Draw the contour plots\n",
        "2.   Explain the hyper-parameters you choose and why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auoYiJQXTNNW"
      },
      "source": [
        "df.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}