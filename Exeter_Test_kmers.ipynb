{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA6gHqgzRFWZ7gX+hq7gBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrankGangWang/AppliedML_Python_Coursera/blob/master/Exeter_Test_kmers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction methods:\n",
        "1. spatial autocorrelation of alist of lags per sample;\n",
        "2. histogram of '1-mer' per sample = 0th markov model;\n",
        "\n",
        "There are 3 general approaches to encoding sequence data:\n",
        "\n",
        "1.   Ordinal encoding DNA Sequence\n",
        "2.   One-hot encoding DNA Sequence\n",
        "3.   DNA sequence as a “language”, known as k-mer counting\n",
        "\n",
        "\n",
        "Ref:\n",
        "\n",
        "https://www.theaidream.com/post/demystify-dna-sequencing-with-machine-learning-and-python\n"
      ],
      "metadata": {
        "id": "zivjTsUMPB8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ordinal encoding DNA sequence data\n",
        "\n",
        "In this approach, we need to encode each nitrogen base as an ordinal value. For example “ATGC” becomes [0.25, 0.5, 0.75, 1.0]. Any other base such as “N” can be a 0.\n",
        "\n",
        "\n",
        "So let us create functions such as creating a NumPy array object from a sequence string, and a label encoder with the DNA sequence alphabet “a”, “c”, “g” and “t”, but also a character for anything else, “n”."
      ],
      "metadata": {
        "id": "h1HSDdPNDGDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ordinal encoding DNA sequence data: 'NATGC'=[0.0, .25,.5, .75, 1.0]\n",
        "# any chars not one of 'atcg' is forced to be 'z' and encoded to be 0.0;\n",
        "import numpy as np\n",
        "import re\n",
        "def string_to_array(seq_string):\n",
        "   seq_string = seq_string.lower()\n",
        "\n",
        "   #anything not 'atcg' will be forced to be 'n'\n",
        "   seq_string = re.sub('[^acgt]', 'z', seq_string)\n",
        "\n",
        "   seq_string = np.array(list(seq_string))\n",
        "   return seq_string\n",
        "\n",
        "# create a label encoder with 'acgtn' alphabet\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))\n",
        "\n",
        "def ordinal_encoder(my_array):\n",
        "   integer_encoded = label_encoder.transform(my_array)\n",
        "   float_encoded = integer_encoded.astype(float)\n",
        "   float_encoded[float_encoded == 0] = 0.25 # A\n",
        "   float_encoded[float_encoded == 1] = 0.50 # C\n",
        "   float_encoded[float_encoded == 2] = 0.75 # G\n",
        "   float_encoded[float_encoded == 3] = 1.00 # T\n",
        "   float_encoded[float_encoded == 4] = 0.00 # anything else, lets say z\n",
        "   return float_encoded\n"
      ],
      "metadata": {
        "id": "W-NHq-OCW6dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://raw.githubusercontent.com/nageshsinghc4/DNA-Sequence-Machine-learning/master/chimp_data.txt\n",
        "a1='ATGCCCCAACTAAATACCGCCGTATGACCCACCATAATTACCCCCATACTCCTGACACTATTTCTCGTCACCCAACTAAAAATATTAAATTCAAATTACCATCTACCCCCCTCACCAAAACCCATAAAAATAAAAAACTACAATAAACCCTGAGAACCAAAATGAACGAAAATCTATTCGCTTCATTCGCTGCCCCCACAATCCTAG\t'\n",
        "a2='ATGAACGAAAATCTATTCGCTTCATTCGCTGCCCCCACAATCCTAGGCTTACCCGCCGCAGTACTAATCATTCTATTCCCCCCTCTACTGGTCCCCACTTCTAAACATCTCATCAACAACCGACTAATTACCACCCAACAATGACTAATTCAACTGACCTCAAAACAAATAATAACTATACACAGCACTAAAGGACGAACCTGATCTCTCATACTAGTATCCTTAATCATTTTTATTACCACAACCAATCTTCTTGGGCTTCTACCCCACTCATTCACACCAACCACCCAACTATCTATAAACCTAGCCATGGCTATCCCCCTATGAGCAGGCGCAGTAGTCATAGGCTTTCGCTTTAAGACTAAAAATGCCCTAGCCCACTTCTTACCGCAAGGCACACCTACACCCCTTATCCCCATACTAGTTATCATCGAAACTATTAGCCTACTCATTCAACCAATAGCCTTAGCCGTACGTCTAACCGCTAACATTACTGCAGGCCACCTACTCATGCACCTAATTGGAAGCGCCACACTAGCATTATCAACTATCAATCTACCCTATGCACTCATTATCTTCACAATTCTAATCCTACTGACTATTCTAGAGATCGCCGTCGCCTTAATCCAAGCCTACGTTTTTACACTTCTAGTGAGCCTCTACCTGCACGACAACACATAA\t'\n",
        "len(a1), len(a2)\n"
      ],
      "metadata": {
        "id": "aWVpBCzODxEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_, label_encoder.transform(['a','c','g','t','z'])"
      ],
      "metadata": {
        "id": "dInze7WjJnt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s try out a simple short sequence:\n",
        "seq_test = 'acgtnTTCAGCCAGTG'\n",
        "print(string_to_array(seq_test), '\\n', \\\n",
        "      label_encoder.transform(string_to_array(seq_test)), '\\n', \\\n",
        "      label_encoder.transform(string_to_array(seq_test)).astype(float), \\\n",
        "      '\\n', ordinal_encoder(string_to_array(seq_test)))"
      ],
      "metadata": {
        "id": "hVwFfnGoXIHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_array(seq_test)"
      ],
      "metadata": {
        "id": "C3Kzy1JiFucY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-hot encoding DNA Sequence\n",
        "\n",
        "Another approach is to use one-hot encoding to represent the DNA sequence. This is widely used in deep learning methods and lends itself well to algorithms like convolutional neural networks. In this example, “ATGC” would become [0,0,0,1], [0,0,1,0], [0,1,0,0], [1,0,0,0]. And these one-hot encoded vectors can either be concatenated or turned into 2-dimensional arrays.\n"
      ],
      "metadata": {
        "id": "1K3DHprVX3i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))\n",
        "\n",
        "def one_hot_encoder(seq_string):\n",
        "  seq_string = string_to_array(seq_string)\n",
        "  int_encoded = label_encoder.transform(seq_string)\n",
        "  print('my int_encoded', int_encoded)\n",
        "\n",
        "  onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
        "  int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
        "  onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n",
        "  onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
        "  return onehot_encoded"
      ],
      "metadata": {
        "id": "fMcist9GXILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So let’s try it out with a simple short sequence:\n",
        "one_hot_encoder('aaccggttbefg')"
      ],
      "metadata": {
        "id": "5eWxufUwEpRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_encoded = label_encoder.transform(string_to_array('ACGTZnv'))\n",
        "onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
        "print('int_encoded', int_encoded)\n",
        "int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
        "onehot_encoder.fit(int_encoded)\n",
        "print('onehot_encoder ', onehot_encoder.categories_)\n",
        "onehot_encoder.transform(int_encoded)"
      ],
      "metadata": {
        "id": "KBOHthnhEpMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DNA sequence as a “language”, known as k-mer counting\n",
        "\n",
        "A hurdle that still remains is that none of these above methods results in vectors of uniform length, and that is a necessity for feeding data to a classification or regression algorithm. So with the above methods, you have to resort to things like truncating sequences or padding with “n” or “0” to get vectors of uniform length.\n",
        "\n",
        "\n",
        "DNA and protein sequences can be seen as the language of life. The language encodes instructions as well as functions for the molecules that are found in all life forms. The sequence language resemblance continues with the genome as the book, subsequences (genes and gene families) are sentences and chapters, k-mers and peptides are words, and nucleotide bases and amino acids are the alphabets. Since the relationship seems so likely, it stands to reason that natural language processing(NLP) should also implement the natural language of DNA and protein sequences.\n",
        "\n",
        "\n",
        "The method we use here is manageable and easy. We first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if we use “words” of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
        "\n",
        "\n",
        "In genomics, we refer to these types of manipulations as “k-mer counting”, or counting the occurrences of each possible k-mer sequence and Python natural language processing tools make it super easy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WjUipZxoYWGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Kmers_funct(seq, size):\n",
        "   return [ seq[x:x+size].lower() for x in range(len(seq) - size + 1) ]"
      ],
      "metadata": {
        "id": "WmHGg5SGXICL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So let’s try it out with a simple sequence:\n",
        "mySeq = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
        "Kmers_wordsize = 6\n",
        "print(len(mySeq)-Kmers_wordsize+1, len(Kmers_funct(mySeq, size=Kmers_wordsize)))\n",
        "print(Kmers_funct(mySeq, size=Kmers_wordsize))"
      ],
      "metadata": {
        "id": "qS9BX7E6UUw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It returns a list of k-mer “words.” You can then join the “words” into a “sentence”, then apply your favorite natural language processing methods to the “sentences” as you normally would.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rEkn6wdHY6gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeq = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
        "words = Kmers_funct(mySeq, size=Kmers_wordsize)\n",
        "print(type(words), len(words), words)\n",
        "joined_sentence = ' '.join(words)\n",
        "print(type(joined_sentence), len(joined_sentence), joined_sentence)\n"
      ],
      "metadata": {
        "id": "6EGOA-pnXH9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "25*Kmers_wordsize +  len(words)-1"
      ],
      "metadata": {
        "id": "oXI3gOpY_V2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tune both the **word length and the amount of overlap**. This allows you to determine how the DNA sequence information and vocabulary size will be important in your application. For example, if you use words of length 6, and there are 4 letters, you have a vocabulary of size pow(4,6)=4096 possible words. You can then go on and create a bag-of-words model like you would in NLP.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "95ly3k6qZMB_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARYSmChuU-pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer() parameters:\n",
        "# ngram_rangetuple (min_n, max_n), default=(1, 1)\n",
        "# analyzer{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’\n"
      ],
      "metadata": {
        "id": "xT3MlCO9lV2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s make a couple more “sentences” to make it more interesting.\n",
        "Kmers_wordsize = 6\n",
        "mySeq = 'CAGGTTCAGTGAGTGACACAGGCAcacag'\n",
        "mySeq1 = 'TCTCACACATGTGCCAATCACTGTCAATCACCC'\n",
        "mySeq2 = 'CAGGTTCAGTGAGTGACACAGGCAcacaga'\n",
        "joined_sentence = ' '.join(Kmers_funct(mySeq, size=Kmers_wordsize))\n",
        "sentence1 = ' '.join(Kmers_funct(mySeq1, size=Kmers_wordsize))\n",
        "sentence2 = ' '.join(Kmers_funct(mySeq2, size=Kmers_wordsize))\n",
        "\n",
        "#Creating the Bag of Words model:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer() # try: ngram_range=(4,4)\n",
        "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()"
      ],
      "metadata": {
        "id": "U5HOeUmnY6A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_dict(vocabulary):\n",
        "  return {k: v for k, v in sorted(vocabulary.items(), key=lambda item: item[1])}\n",
        "\n",
        "print('fixed_vocabulary_=', cv.fixed_vocabulary_, type(cv.vocabulary_), len(cv.vocabulary_.keys()))\n",
        "print('vocabulary_=', sort_dict(cv.vocabulary_))\n",
        "print('X shape=', X.shape, '\\nX[0] X[1] same num=', sum(X[0]==X[1]), '\\nX[0] X[2] same num=', sum(X[0]==X[2]), \\\n",
        "      '\\nX[2] X[1] diff num=', sum(X[1]==X[2]), '\\n', X)"
      ],
      "metadata": {
        "id": "JPxpl6l1eG6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is the first document of this document and I have it, and I lost the document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third AND one.',\n",
        "    'Is this the first document, is it?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()\n",
        "tmp = {k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
        "\n",
        "print(X.shape, len(tmp), tmp, '\\n', len(vectorizer.vocabulary_.items()), '\\n', X.toarray())\n"
      ],
      "metadata": {
        "id": "lt6YY5hGXAd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "vectorizer2.get_feature_names_out()"
      ],
      "metadata": {
        "id": "HTjO9_nXXAaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SaIC5k4RXAWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE4ZQauAXATx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPruR6D1XAQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDK8zB75XAM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TDpNIkrXAJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(len(sentence1), len(mySeq1), len(sentence1.split()))\n",
        "print(len(sentence2), len(mySeq2), len(sentence2.split()) )\n",
        "print(len(joined_sentence), len(mySeq), len(joined_sentence.split()))\n",
        "\n"
      ],
      "metadata": {
        "id": "4i865zuziGUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X)"
      ],
      "metadata": {
        "id": "misUvAMSWBx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=(np.unique([joined_sentence, sentence1, sentence2]))\n",
        "type(x), x.shape, x.size, x.data\n",
        "\n"
      ],
      "metadata": {
        "id": "exPzj8tUimHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(np.unique(joined_sentence.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence1.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence2.split())),\\\n",
        "  len(np.unique(joined_sentence.split()+ sentence1.split()+ sentence2.split())))\n"
      ],
      "metadata": {
        "id": "ZduAm2u4ld6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "Zdefe5Hch8sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('joined_sentence=',joined_sentence, '\\n', 'sentence1=\\t', sentence1, '\\n','sentence2=\\t',sentence2)\n"
      ],
      "metadata": {
        "id": "b7C3EpemY57n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Bag of Words model:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()\n"
      ],
      "metadata": {
        "id": "b1iyuyK0g8oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the term k-mer refers to all of a sequence's subsequences of length k, such that the sequence AGAT would have four monomers (A, G, A, and T), three 2-mers (AG, GA, AT), two 3-mers (AGA and GAT) and one 4-mer (AGAT). More generally, a sequence of length L will have L+K-1 k-mers and n^k total possible k-mers, where\n",
        "n is number of possible monomers (e.g. four in the case of DNA).\n"
      ],
      "metadata": {
        "id": "J2h--2Fmg2Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here comes machine learning…\n",
        "\n",
        "\n",
        "Now that we have learned how to extract feature matrices from the DNA sequence, let us apply our newly acquired knowledge to a real-life machine learning use case.\n",
        "\n",
        "\n",
        "Use case: Build a classification model that is trained on the human DNA sequence and can predict a gene family based on the DNA sequence of the coding sequence. To test the model, we will use the DNA sequence of humans, dogs, and chimpanzees and compare the accuracies.\n",
        "\n",
        "Gene families are groups of related genes that share a common ancestor. Members of gene families may be paralogs or orthologs. Gene paralogs are genes with similar sequences from within the same species while gene orthologs are genes with similar sequences in different species.\n",
        "\n",
        "\n",
        "The dataset contains human DNA sequence, Dog DNA sequence, and Chimpanzee DNA sequence.\n",
        "\n",
        "\n",
        "Load the human DNA sequence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wRoHTr1IgHC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "human_dna = pd.read_table('./drive/My Drive/human_data.txt')\n",
        "human_dna.head()"
      ],
      "metadata": {
        "id": "r50Orqv3Y53P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtH-zCbUhtuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gy9hoKSOhtot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opKm_-HLhtiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#outlier detection\n"
      ],
      "metadata": {
        "id": "YG07FruBC3B8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBtNTKRvQ30s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBhzIuZkm4Zp"
      },
      "outputs": [],
      "source": [
        "# extract the unique chars in all samples\n",
        "\n",
        "chars_list = set()\n",
        "f = open(\"test.txt\", \"r\")\n",
        "count_chars = 0\n",
        "\n",
        "def func_count_unique_chars(line, counter):\n",
        "  \"\"\"func to get unique chars in 'line' based on current 'counter'.\n",
        "  Note: set counter = set() for the first line;\n",
        "  \"\"\"\n",
        "  for c in line:\n",
        "    counter.add(c)\n",
        "  return (counter)\n",
        "  #sorted(set) returns a list\n",
        "\n",
        "for number_of_lines, line in enumerate(f):\n",
        "  line = line.rstrip('\\n')\n",
        "  count_chars += len(line)\n",
        "  chars_list = func_count_unique_chars(line, chars_list)\n",
        "  if number_of_lines<5:\n",
        "    print(f'Line {number_of_lines}:\\t{len(line)} chars, total ={count_chars},\\\n",
        "            last 5 chars ={line[-5:]}, uniques={sorted(chars_list)}')\n",
        "\n",
        "f.close()\n",
        "number_of_lines = number_of_lines + 1\n",
        "chars_list = sorted(chars_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of lines =\\t', number_of_lines)\n",
        "print('number of chars =\\t', count_chars)\n",
        "print('unique chars =', chars_list)"
      ],
      "metadata": {
        "id": "zRDgBBtanWfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b455474-8978-4da0-c1be-26a2e8c22540"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines =\t 300\n",
            "number of chars =\t 32363\n",
            "unique chars = ['C', 'D', 'E', 'F', 'G']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "AMcQdvOQsDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = func_count_chars_ordered('ABC CCD DDD', chars_list)\n",
        "tmp = [{chars_list[id]:tmp[id]} for id in range(len(chars_list))]\n",
        "print(chars_list, tmp)"
      ],
      "metadata": {
        "id": "R20I5z32stRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate features as the histogram of unique chars in chars_list;\n",
        "# equivalent to 0th order markov chain model;\n",
        "# chars_list is ['C', 'D', 'E', 'F', 'G'] for this data;\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def func_count_chars_ordered(line, chars):\n",
        "  \"\"\"func to count number of strings in string 'line' based on current 'counter'.\n",
        "  Note: set counter = {} for the first line;\n",
        "  \"\"\"\n",
        "  counter = np.zeros((len(chars, )))\n",
        "  #print(counter, line, chars)\n",
        "  for id, c in enumerate(chars):\n",
        "    #print(f'id={id}, ch={chars[id]}')\n",
        "    counter[id] = line.count(chars[id])\n",
        "  return counter\n",
        "df = np.zeros((number_of_lines, len(chars_list)))\n",
        "print(chars_list, df.shape)\n",
        "\n",
        "f = open(\"test.txt\", \"r\")\n",
        "for c, line in enumerate(f):\n",
        "  if c<5:\n",
        "    print(f'***num of chars in line {c} is {len(line), {line[-5:]}}')\n",
        "  line = line.rstrip('\\n')\n",
        "  df[c] = func_count_chars_ordered(line, chars_list)\n",
        "f.close()\n",
        "\n",
        "df = pd.DataFrame(df, columns=chars_list)\n"
      ],
      "metadata": {
        "id": "tQXxDN2EnWbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312ffa46-226e-4686-f75b-abcb92b914a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C', 'D', 'E', 'F', 'G'] (300, 5)\n",
            "***num of chars in line 0 is (106, {'DEGE\\n'})\n",
            "***num of chars in line 1 is (114, {'CEGE\\n'})\n",
            "***num of chars in line 2 is (114, {'CEGC\\n'})\n",
            "***num of chars in line 3 is (113, {'CGCE\\n'})\n",
            "***num of chars in line 4 is (116, {'EGEE\\n'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "S0nT7ir6YFe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "oj6jEjZMnWYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc5e6dd-6102-4e8d-d143-8c0c5d4225c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300 entries, 0 to 299\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   C       300 non-null    float64\n",
            " 1   D       300 non-null    float64\n",
            " 2   E       300 non-null    float64\n",
            " 3   F       300 non-null    float64\n",
            " 4   G       300 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 11.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.loc[0, df.columns[0]]), (df.loc[0, df.columns[0]][-5:]), ('\\n' in df.loc[0, df.columns[0]]), ('D' in df.loc[0, df.columns[0]]))\n",
        "print(len(df.loc[0, 'sequence']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlKowUVL9KMD",
        "outputId": "42109212-7f8f-4dec-b474-888d7d6ec01f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105 GDEGE False True\n",
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-mers\n",
        "# generate features k-mers per sample;\n",
        "# equivalent to simplified (k-1)th order markov chain model;\n",
        "# chars_list is ['C', 'D', 'E', 'F', 'G'] for this data;\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "kmers_size = 6\n",
        "#df = np.zeros((number_of_lines, len(chars_list)))\n",
        "df = pd.read_table(\"test.txt\", header=None, names=['sequence'])\n",
        "df.head()\n",
        "def func_Kmers(seq, size=6):\n",
        "   return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]\n",
        "#convert our training data sequences into short overlapping k-mers of length 6.\n",
        "#Lets do that for each species of data we have using our Kmers_funct function.\n",
        "\n",
        "df[f'{kmers_size}-mers'] = df.apply(lambda x: func_Kmers(x[df.columns[0]], kmers_size), axis=1)\n",
        "df = df.drop(df.columns[0], axis=1)\n",
        "\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GBKCrT0JYhwS",
        "outputId": "e881d0dc-7ae4-40dd-be2a-618e6f233b95"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              6-mers\n",
              "0  [edgcdg, dgcdge, gcdgee, cdgeef, dgeefc, geefc...\n",
              "1  [egedgc, gedgcd, edgcdg, dgcdge, gcdgef, cdgef...\n",
              "2  [eeedge, eedged, edgedg, dgedge, gedgec, edgec..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe1f3e8c-c0f3-46d8-8744-ff77207b08fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6-mers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[edgcdg, dgcdge, gcdgee, cdgeef, dgeefc, geefc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[egedgc, gedgcd, edgcdg, dgcdge, gcdgef, cdgef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[eeedge, eedged, edgedg, dgedge, gedgec, edgec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe1f3e8c-c0f3-46d8-8744-ff77207b08fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe1f3e8c-c0f3-46d8-8744-ff77207b08fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe1f3e8c-c0f3-46d8-8744-ff77207b08fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d322d37c-52c4-42d2-a1ad-7400b2c8496d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d322d37c-52c4-42d2-a1ad-7400b2c8496d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d322d37c-52c4-42d2-a1ad-7400b2c8496d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(5):\n",
        "  print(len(df.loc[k, df.columns[0]]), type(df.loc[k, df.columns[0]]), (df.loc[k, df.columns[0]][-5:]))\n",
        "  #print('\\n' in df.loc[0, df.columns[0]], 'D' in df.loc[0, df.columns[0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlx4zgSn75kf",
        "outputId": "fe887f9b-b258-4970-fe3f-7eced3a2e854"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 <class 'list'> ['cfcggg', 'fcgggd', 'cgggde', 'gggdeg', 'ggdege']\n",
            "108 <class 'list'> ['degecg', 'egecgc', 'gecgce', 'ecgceg', 'cgcege']\n",
            "108 <class 'list'> ['degecg', 'egecgc', 'gecgce', 'ecgceg', 'cgcegc']\n",
            "107 <class 'list'> ['ggdege', 'gdegec', 'degecg', 'egecgc', 'gecgce']\n",
            "110 <class 'list'> ['egecgc', 'gecgce', 'ecgceg', 'cgcege', 'gcegee']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "We need to now convert the lists of k-mers for each gene into string sentences of words that can be used to create the Bag of Words model. We will make a target variable y to hold the class labels."
      ],
      "metadata": {
        "id": "_a_fXLQGDsnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2fGsipJ-EGsu",
        "outputId": "bf2fb699-77bd-4930-e12d-a3fc35713663"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6-mers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#do the same for chimp and dog\n",
        "human_texts = list(df[df.columns[0]])\n",
        "for item in range(len(human_texts)):\n",
        "   human_texts[item] = ' '.join(human_texts[item])\n",
        "#separate labels\n",
        "y_human = df.iloc[:, 0].values # y_human for human_dna\n",
        "\n",
        "#So the target variable contains an array of class values.\n",
        "#array([4, 4, 3, …, 6, 6, 6])\n"
      ],
      "metadata": {
        "id": "KSLs2wTE75AS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_human.shape, len(human_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvOdTBi_6Xs9",
        "outputId": "ea5cfc90-4636-4eb8-c828-cab84990db4d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300,), 300)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Bag of Words model:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(ngram_range=(1, 1))\n",
        "#The n-gram size of 4 is previously determined by testing\n",
        "# analyzer{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’\n",
        "\n",
        "X = cv.fit_transform(human_texts)\n",
        "\n",
        "\n",
        "#You may want to check the shape of each of these training data.\n",
        "print(X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yimWee2PEsqF",
        "outputId": "46313275-e3b7-4347-b6bb-3897fb758ba5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 5769)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1mOFreYEslz",
        "outputId": "3787212c-05a0-417d-dd11-fcb3b9c8d3ea"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn1DKpVYFQzK",
        "outputId": "c8fed626-7187-4f3c-8c08-e2a1448f2f33"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x5769 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 312 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0:3].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpdqQm4oEsjE",
        "outputId": "48311a19-40d8-48de-da4a-f38f2fceaebf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeqOOnFKEscl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghx6KFHcEsZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-2x1jSe6Xoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(5)\n",
        "x = np.cumsum(np.random.normal(loc=1, scale=5, size=50))\n",
        "s = pd.Series(x)\n",
        "s.plot()"
      ],
      "metadata": {
        "id": "_SbNNjhaZWVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.lag_plot(s, lag=1)"
      ],
      "metadata": {
        "id": "McF3KDjUZkyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lag = 2\n",
        "for col in df.columns:\n",
        "  plt.figure()\n",
        "  pd.plotting.lag_plot(df[col], lag=lag)\n",
        "  plt.grid()\n"
      ],
      "metadata": {
        "id": "RwR8T99xZsln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "  #plt.figure()\n",
        "  plt.plot(df.loc[:, [col]])\n",
        "plt.legend(df.columns, loc='upper right')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "AHCoYs80b-6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.plotting.lag_plot(df.loc[:, [\"C\"]], lag=1)\n",
        "import matplotlib.pyplot as plt\n",
        "for col in df.columns:\n",
        "  #plt.figure()\n",
        "  pd.plotting.autocorrelation_plot(df.loc[:, [col]])\n",
        "plt.legend(df.columns, loc='upper right')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "INyEKGhNYpUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lag in range(1,5):\n",
        "  plt.figure()\n",
        "  pd.plotting.lag_plot(df, lag=lag)\n"
      ],
      "metadata": {
        "id": "SoVGprmBXEJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars_list"
      ],
      "metadata": {
        "id": "7YFEYJnoWxXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "7qJJTIAmhIQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "# calculate summary statistics\n",
        "data_mean, data_std = mean(df), std(df)\n",
        "# identify outliers\n",
        "cut_off = data_std * 2\n",
        "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
        "print(f'data_mean=\\n{data_mean}, data_std=\\n{data_std}')\n",
        "print(f'lower=\\n{lower}, upper=\\n{upper}')"
      ],
      "metadata": {
        "id": "qODl28qahidQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_idx, ch, df.loc[outliers_idx, ch]"
      ],
      "metadata": {
        "id": "kWTINzoqizAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identify outliers\n",
        "for ch in chars_list:\n",
        "  outliers = [x for x in df[ch] if x < lower[ch] or x > upper[ch]]\n",
        "  outliers_idx = df.index[df[ch]==outliers[0]].tolist()\n",
        "  #print(ch, outliers, '\\n', outliers_idx, '\\n')\n",
        "  print(outliers_idx)\n"
      ],
      "metadata": {
        "id": "DhY1tZUgnWSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: outlier is\n",
        "269 by 'C, G' \\\n",
        "161 by 'C, D' \\\n"
      ],
      "metadata": {
        "id": "ILmPBejPjX1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column=['C', 'D', 'F'])\n"
      ],
      "metadata": {
        "id": "bYO2UnXImvi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column=['E', 'G'])"
      ],
      "metadata": {
        "id": "TvjTXry2mz9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot()"
      ],
      "metadata": {
        "id": "V6GSoKOzm1p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "#Note that neighbors.LocalOutlierFactor does not support predict, decision_function\n",
        "#and score_samples methods by default but only a fit_predict method, as this estimator\n",
        "#was originally meant to be applied for outlier detection. The scores of abnormality\n",
        "#of the training samples are accessible through the negative_outlier_factor_ attribute.\n",
        "\n",
        "n_neighbors = 150\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df) #\n",
        "print(np.where(results==-1))\n",
        "#estimator.predict(X_test): Inliers are labeled 1, while outliers are labeled -1.\n",
        "#clf.negative_outlier_factor_\n",
        "#The decision_function method is also defined from the scoring function, in such\n",
        "#a way that negative values are outliers and non-negative ones are inliers:\n",
        "#estimator.decision_function(X_test)\n",
        "\n",
        "#negative_outlier_factor_: The opposite LOF of the training samples. The higher, the more normal.\n",
        "#Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1), while outliers tend to have a larger LOF score.\n"
      ],
      "metadata": {
        "id": "QXew3phhmh2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LocalOutlierFactor example\n",
        "import numpy as np\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "X = [[-1.1], [0.2], [11.1], [-111.3]]\n",
        "clf = LocalOutlierFactor(n_neighbors=2)\n",
        "results = clf.fit_predict(X)\n",
        "print(f'results={results}')\n",
        "print(f'negative_outlier_factor_={clf.negative_outlier_factor_}')\n",
        "print(f'outlier index={np.where(results==-1)}')"
      ],
      "metadata": {
        "id": "8TZtoIWx2NVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "n_neighbors = 20\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "results = clf.fit_predict(df)\n",
        "outlier_idx = np.where(results==-1)\n",
        "print(f'outlier index={outlier_idx}')\n",
        "print(f'outlier results={results[outlier_idx]}')\n",
        "print(f'outlier negative_outlier_factor_={clf.negative_outlier_factor_[outlier_idx]}')\n",
        "print(f'first 10 negative_outlier_factor_={clf.negative_outlier_factor_[:10]}')"
      ],
      "metadata": {
        "id": "kg2eQRusmNRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot()"
      ],
      "metadata": {
        "id": "H-oMXChFoxIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "outliers as indicated by out of range of mean by 2*std:\\\n",
        "Conclusion: outlier with shared columns is:\\\n",
        "161 by 'C, D' \\\n",
        "269 by 'C, G' \\\n",
        "\n",
        "C [50, 77, 161, 170, 265, 269]\\\n",
        "D [24, 63, 100, 104, 122, 133, 151, 154, 159, 161, 164, 169, 187, 202, 228, 252]\\\n",
        "E [11, 25, 135, 141, 166, 283, 287]\\\n",
        "F [13, 54, 56, 147, 152, 154, 155, 163, 176]\\\n",
        "G [94, 269]\\\n",
        "\n"
      ],
      "metadata": {
        "id": "vVMf204HnSTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "n_neighbors = 2\n",
        "clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "#results = clf.fit_predict(df[['G']])\n",
        "results = clf.fit_predict(df)\n",
        "\n",
        "outlier_idx = np.where(results==-1)\n",
        "print(f'outlier index={outlier_idx}')\n",
        "print(f'outlier results={results[outlier_idx]}')\n",
        "print(f'outlier negative_outlier_factor_={clf.negative_outlier_factor_[outlier_idx]}')\n",
        "print(f'first 10 negative_outlier_factor_={clf.negative_outlier_factor_[:10]}')"
      ],
      "metadata": {
        "id": "O-zaILWG2NRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py\n",
        "\n",
        "Outlier detection with Local Outlier Factor (LOF)\n"
      ],
      "metadata": {
        "id": "DVmYbnlqPDS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X_inliers = 0.3 * np.random.randn(100, 2)\n",
        "X_inliers = np.r_[X_inliers + 2, X_inliers - 2]\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "X = np.r_[X_inliers, X_outliers]\n",
        "\n",
        "n_outliers = len(X_outliers)\n",
        "ground_truth = np.ones(len(X), dtype=int)\n",
        "ground_truth[-n_outliers:] = -1"
      ],
      "metadata": {
        "id": "EqeZWZAWPETq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_inliers.shape, np.random.randn(100, 2).shape, X_outliers.shape, n_outliers, X.shape"
      ],
      "metadata": {
        "id": "u-OwZoqePaj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbYzTOmxPaUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "y_pred = clf.fit_predict(X)\n",
        "n_errors = (y_pred != ground_truth).sum()\n",
        "X_scores = clf.negative_outlier_factor_"
      ],
      "metadata": {
        "id": "tlygJ2moPN77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.legend_handler import HandlerPathCollection\n",
        "\n",
        "\n",
        "def update_legend_marker_size(handle, orig):\n",
        "    \"Customize size of the legend marker\"\n",
        "    handle.update_from(orig)\n",
        "    handle.set_sizes([20])\n",
        "\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], color=\"k\", s=3.0, label=\"Data points\")\n",
        "# plot circles with radius proportional to the outlier scores\n",
        "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
        "scatter = plt.scatter(\n",
        "    X[:, 0],\n",
        "    X[:, 1],\n",
        "    s=1000 * radius,\n",
        "    edgecolors=\"r\",\n",
        "    facecolors=\"none\",\n",
        "    label=\"Outlier scores\",\n",
        ")\n",
        "plt.axis(\"tight\")\n",
        "plt.xlim((-5, 5))\n",
        "plt.ylim((-5, 5))\n",
        "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
        "plt.legend(\n",
        "    handler_map={scatter: HandlerPathCollection(update_func=update_legend_marker_size)}\n",
        ")\n",
        "plt.title(\"Local Outlier Factor (LOF)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jgldZkclPQUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Anomaly Detection using Unsupervised KNN\n",
        "\n",
        "Ref: https://www.kaggle.com/code/kimchanyoung/simple-anomaly-detection-using-unsupervised-knn\n",
        "\n",
        "KNN is a supervised learning-based algorithm.\n",
        "However, using KNN's distance calculation method can also be used as an unsupervised learning method.\n",
        "\n",
        "In this work, we will use Scikit-Learn's NearestNeighbors, which we can use it for unsupervised learning\n",
        "\n",
        "sklearn.neighbors.NearestNeighbors\n",
        "class sklearn.neighbors.NearestNeighbors(*, n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None)\n",
        "n_neighbors : int, default=5 (Number of neighbors to use by default for kneighbors queries.)\n",
        "radius : float, default=1.0 (Range of parameter space to use by default for radius_neighbors queries.)\n",
        "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’ (Algorithm used to compute the nearest neighbors)\n",
        "metric : str or callable, default=’minkowski’ (the distance metric to use for the tree.)\n",
        "p : int, default=2 (Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HEUu5NZzxWLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "7yP-lM5AxW0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "LtXSY5_uxk31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "plt.scatter(df[\"C\"], df[\"D\"], color='Red')\n",
        "ax.set_xlabel('C', fontsize='11')\n",
        "ax.set_ylabel('D', fontsize='11')\n",
        "plt.title('C vs D frequency')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5NBX96Wyxi0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "n_neighbors = 10\n",
        "nbrs = NearestNeighbors(n_neighbors = n_neighbors)\n",
        "# fit model\n",
        "nbrs.fit(df)\n"
      ],
      "metadata": {
        "id": "nMLmoVmayQf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distances and indexes of k-neaighbors from model outputs\n",
        "distances, indexes = nbrs.kneighbors(df)\n",
        "# plot\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.plot(distances.mean(axis =1))"
      ],
      "metadata": {
        "id": "zP-kVsmkyWBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances = pd.DataFrame(distances)\n",
        "distances_mean = distances.mean(axis =1)\n",
        "distances_mean"
      ],
      "metadata": {
        "id": "j5eNQFoEyV98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances"
      ],
      "metadata": {
        "id": "Rsx6yNCPyV6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set thresholds with reference to statistics.\n",
        "\n",
        "distances_mean.describe()\n"
      ],
      "metadata": {
        "id": "WrsqxAtwyV3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linspace(0, 3, num=4)"
      ],
      "metadata": {
        "id": "VnB2uyhY0Rmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Since 75th percentile is 8.35, we will set threshold into 9.0\n",
        "#Since 75th percentile is 1.32, we will set threshold into 1.5\n",
        "for th in np.linspace(1.9, 3, num=5):\n",
        "  outlier_index = np.where(distances_mean > th)\n",
        "  print(th, len(list(outlier_index[0])), outlier_index)\n"
      ],
      "metadata": {
        "id": "de2UFlpOyVvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_values = df.iloc[outlier_index]\n",
        "outlier_values"
      ],
      "metadata": {
        "id": "iBo4gKE1zn_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_values"
      ],
      "metadata": {
        "id": "1c3DEHBm7VRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, len(chars_list), figsize=(15, 6), facecolor='w', edgecolor='k')\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i in range(0, len(chars_list)):\n",
        "    axs[i].plot(df[chars_list[i]], color = \"b\", marker=\"+\")\n",
        "    axs[i].plot(outlier_values[chars_list[i]], color='r', marker=\"o\") #s=80, facecolors='none', edgecolors='r'\n",
        "    axs[i].set_title(chars_list[i])"
      ],
      "metadata": {
        "id": "0ywwIRDp2Vei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, len(chars_list)-1, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i in range(1, len(chars_list)):\n",
        "    axs[i-1].scatter(df[\"C\"], df[chars_list[i]], color = \"b\", marker=\"+\")\n",
        "    axs[i-1].scatter(outlier_values[\"C\"], outlier_values[chars_list[i]], marker=\"o\", s=80, facecolors='none', edgecolors='r')\n",
        "    axs[i-1].set_title(chars_list[i])"
      ],
      "metadata": {
        "id": "JgE12m533fe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion of outlier with single feature separately:\n",
        "269 by 'C, G' \\\n",
        "161 by 'C, D' \\"
      ],
      "metadata": {
        "id": "KpXqjv_5zU5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Isolation Forest\n",
        "One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The ensemble.IsolationForest ‘isolates’ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.\n"
      ],
      "metadata": {
        "id": "AlZYa5Sv7wBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#max_features int or float, default=1.0\n",
        "The number of features to draw from X to train each base estimator.\n",
        "\n",
        "If int, then draw max_features features.\n",
        "\n",
        "If float, then draw max(1, int(max_features * n_features_in_)) features.\n",
        "\n",
        "Note: using a float number less than 1.0 or integer less than number of features will enable feature subsampling and leads to a longer runtime.\n"
      ],
      "metadata": {
        "id": "Ws_G0lFS8LFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "clf = IsolationForest(max_samples=100, random_state=0) #len(chars_list))\n",
        "clf.fit(df)"
      ],
      "metadata": {
        "id": "Y8ZbeQJU7vfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.n_features_in_, clf.feature_names_in_"
      ],
      "metadata": {
        "id": "E2k_JDhiAWde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict if a particular sample is an outlier or not.\n",
        "results = clf.predict(df)\n",
        "outlier_idx = np.where(results==-1)\n",
        "print(f'num of outliers = {len(outlier_idx[0])}, outlier_idx={outlier_idx}')"
      ],
      "metadata": {
        "id": "gsfM5PGW_UBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.shape, len(outlier_idx[0])"
      ],
      "metadata": {
        "id": "ZiT7Xm4TBk89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Opposite of the anomaly score defined in the original paper.\n",
        "results = clf.score_samples(df)\n",
        "plt.plot(range(300), results)\n",
        "plt.plot(outlier_idx[0], results[outlier_idx[0]], 'r+')"
      ],
      "metadata": {
        "id": "Ci6A06x8A7zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results[outlier_idx])\n"
      ],
      "metadata": {
        "id": "lm7ERkCEBK5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = IsolationForest(max_samples=100, random_state=0, max_features=2) #len(chars_list))\n",
        "clf.fit(df[['C', 'D']])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "disp = DecisionBoundaryDisplay.from_estimator(\n",
        "    clf,\n",
        "    df[['C', 'D']],\n",
        "    response_method=\"predict\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "disp.ax_.scatter(df['C'], df['D'], s=20, edgecolor=\"k\")\n",
        "disp.ax_.set_title(\"Binary decision boundary \\nof IsolationForest\")\n",
        "plt.axis(\"square\")\n",
        "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2CNGTw0h8KuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}